


  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::                (v3.0.6)

2023-05-18T18:57:49.284+03:00  INFO 8268 --- [  restartedMain] c.a.spring.boot.kafka.KafkaApplication   : Starting KafkaApplication using Java 17.0.6 with PID 8268 (C:\Users\aziub\git\SpringBoot\kafka\target\classes started by aziub in C:\Users\aziub\git\SpringBoot\kafka)
2023-05-18T18:57:49.302+03:00  INFO 8268 --- [  restartedMain] c.a.spring.boot.kafka.KafkaApplication   : No active profile set, falling back to 1 default profile: "default"
2023-05-18T18:57:49.391+03:00  INFO 8268 --- [  restartedMain] .e.DevToolsPropertyDefaultsPostProcessor : Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2023-05-18T18:57:49.391+03:00  INFO 8268 --- [  restartedMain] .e.DevToolsPropertyDefaultsPostProcessor : For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2023-05-18T18:57:51.124+03:00  INFO 8268 --- [  restartedMain] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 8080 (http)
2023-05-18T18:57:51.143+03:00  INFO 8268 --- [  restartedMain] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2023-05-18T18:57:51.144+03:00  INFO 8268 --- [  restartedMain] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/10.1.8]
2023-05-18T18:57:51.276+03:00  INFO 8268 --- [  restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2023-05-18T18:57:51.279+03:00  INFO 8268 --- [  restartedMain] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 1885 ms
2023-05-18T18:57:52.158+03:00  INFO 8268 --- [  restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : LiveReload server is running on port 35729
2023-05-18T18:57:52.293+03:00  INFO 8268 --- [  restartedMain] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8080 (http) with context path ''
2023-05-18T18:57:52.464+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-4nmjv.francecentral.azure.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_id-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-05-18T18:57:52.641+03:00  INFO 8268 --- [  restartedMain] o.a.k.c.s.authenticator.AbstractLogin    : Successfully logged in.
2023-05-18T18:57:52.825+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.2
2023-05-18T18:57:52.827+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: b66af662e61082cb
2023-05-18T18:57:52.827+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1684425472823
2023-05-18T18:57:52.831+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-group_id-1, groupId=group_id] Subscribed to topic(s): customer_visit_event_backup
2023-05-18T18:57:52.844+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-4nmjv.francecentral.azure.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_id-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-05-18T18:57:52.858+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.2
2023-05-18T18:57:52.858+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: b66af662e61082cb
2023-05-18T18:57:52.858+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1684425472858
2023-05-18T18:57:52.859+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-group_id-2, groupId=group_id] Subscribed to topic(s): customer_visit_event_backup
2023-05-18T18:57:52.862+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-4nmjv.francecentral.azure.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_id2-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-05-18T18:57:52.873+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.2
2023-05-18T18:57:52.874+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: b66af662e61082cb
2023-05-18T18:57:52.874+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1684425472873
2023-05-18T18:57:52.875+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Subscribed to topic(s): customer_visit_event_backup
2023-05-18T18:57:52.908+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-4nmjv.francecentral.azure.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_id-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-05-18T18:57:52.918+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.2
2023-05-18T18:57:52.919+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: b66af662e61082cb
2023-05-18T18:57:52.919+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1684425472918
2023-05-18T18:57:52.920+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-group_id-4, groupId=group_id] Subscribed to topic(s): customer_visit_event_backup
2023-05-18T18:57:52.923+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-4nmjv.francecentral.azure.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_id3-5
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id3
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-05-18T18:57:52.931+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.2
2023-05-18T18:57:52.932+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: b66af662e61082cb
2023-05-18T18:57:52.932+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1684425472931
2023-05-18T18:57:52.932+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-group_id3-5, groupId=group_id3] Subscribed to topic(s): customer_visit_event_backup
2023-05-18T18:57:52.936+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-4nmjv.francecentral.azure.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_id3-6
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id3
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-05-18T18:57:52.945+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.2
2023-05-18T18:57:52.945+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: b66af662e61082cb
2023-05-18T18:57:52.945+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1684425472945
2023-05-18T18:57:52.945+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] Subscribed to topic(s): customer_visit_event_backup
2023-05-18T18:57:52.960+03:00  INFO 8268 --- [  restartedMain] c.a.spring.boot.kafka.KafkaApplication   : Started KafkaApplication in 4.267 seconds (process running for 5.086)
2023-05-18T18:57:54.300+03:00  INFO 8268 --- [ntainer#3-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-2, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-0 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.300+03:00  INFO 8268 --- [ntainer#4-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Resetting the last seen epoch of partition customer_visit_event_backup-0 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.301+03:00  INFO 8268 --- [ntainer#5-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-4, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-0 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.301+03:00  INFO 8268 --- [ntainer#3-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-2, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-5 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.301+03:00  INFO 8268 --- [ntainer#4-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Resetting the last seen epoch of partition customer_visit_event_backup-5 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.302+03:00  INFO 8268 --- [ntainer#4-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Resetting the last seen epoch of partition customer_visit_event_backup-4 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.302+03:00  INFO 8268 --- [ntainer#3-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-2, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-4 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.302+03:00  INFO 8268 --- [ntainer#5-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-4, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-5 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.302+03:00  INFO 8268 --- [ntainer#4-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Resetting the last seen epoch of partition customer_visit_event_backup-1 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.302+03:00  INFO 8268 --- [ntainer#3-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-2, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-1 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.302+03:00  INFO 8268 --- [ntainer#5-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-4, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-4 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.302+03:00  INFO 8268 --- [ntainer#4-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Resetting the last seen epoch of partition customer_visit_event_backup-2 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.302+03:00  INFO 8268 --- [ntainer#5-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-4, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-1 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.302+03:00  INFO 8268 --- [ntainer#3-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-2, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-2 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.302+03:00  INFO 8268 --- [ntainer#4-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Resetting the last seen epoch of partition customer_visit_event_backup-3 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.302+03:00  INFO 8268 --- [ntainer#3-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-2, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-3 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.302+03:00  INFO 8268 --- [ntainer#5-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-4, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-2 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.302+03:00  INFO 8268 --- [ntainer#5-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-4, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-3 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.306+03:00  INFO 8268 --- [ntainer#3-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-2, groupId=group_id] Cluster ID: lkc-3rx3p2
2023-05-18T18:57:54.306+03:00  INFO 8268 --- [ntainer#4-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Cluster ID: lkc-3rx3p2
2023-05-18T18:57:54.306+03:00  INFO 8268 --- [ntainer#5-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-4, groupId=group_id] Cluster ID: lkc-3rx3p2
2023-05-18T18:57:54.308+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Discovered group coordinator b0-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 2147483647 rack: null)
2023-05-18T18:57:54.308+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-4, groupId=group_id] Discovered group coordinator b4-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 2147483643 rack: null)
2023-05-18T18:57:54.308+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-2, groupId=group_id] Discovered group coordinator b4-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 2147483643 rack: null)
2023-05-18T18:57:54.310+03:00  INFO 8268 --- [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-5, groupId=group_id3] Resetting the last seen epoch of partition customer_visit_event_backup-0 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.310+03:00  INFO 8268 --- [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-5, groupId=group_id3] Resetting the last seen epoch of partition customer_visit_event_backup-5 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.310+03:00  INFO 8268 --- [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-5, groupId=group_id3] Resetting the last seen epoch of partition customer_visit_event_backup-4 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.310+03:00  INFO 8268 --- [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-5, groupId=group_id3] Resetting the last seen epoch of partition customer_visit_event_backup-1 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.310+03:00  INFO 8268 --- [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-5, groupId=group_id3] Resetting the last seen epoch of partition customer_visit_event_backup-2 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.311+03:00  INFO 8268 --- [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-5, groupId=group_id3] Resetting the last seen epoch of partition customer_visit_event_backup-3 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.311+03:00  INFO 8268 --- [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-5, groupId=group_id3] Cluster ID: lkc-3rx3p2
2023-05-18T18:57:54.312+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-5, groupId=group_id3] Discovered group coordinator b8-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 2147483639 rack: null)
2023-05-18T18:57:54.319+03:00  INFO 8268 --- [ntainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] Resetting the last seen epoch of partition customer_visit_event_backup-0 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.319+03:00  INFO 8268 --- [ntainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] Resetting the last seen epoch of partition customer_visit_event_backup-5 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.319+03:00  INFO 8268 --- [ntainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] Resetting the last seen epoch of partition customer_visit_event_backup-4 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.320+03:00  INFO 8268 --- [ntainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] Resetting the last seen epoch of partition customer_visit_event_backup-1 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.320+03:00  INFO 8268 --- [ntainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] Resetting the last seen epoch of partition customer_visit_event_backup-2 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.320+03:00  INFO 8268 --- [ntainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] Resetting the last seen epoch of partition customer_visit_event_backup-3 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.321+03:00  INFO 8268 --- [ntainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] Cluster ID: lkc-3rx3p2
2023-05-18T18:57:54.321+03:00  INFO 8268 --- [ntainer#2-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-1, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-0 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.321+03:00  INFO 8268 --- [ntainer#2-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-1, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-5 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.321+03:00  INFO 8268 --- [ntainer#2-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-1, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-4 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.321+03:00  INFO 8268 --- [ntainer#2-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-1, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-1 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.321+03:00  INFO 8268 --- [ntainer#2-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-1, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-2 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.321+03:00  INFO 8268 --- [ntainer#2-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-1, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-3 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:57:54.321+03:00  INFO 8268 --- [ntainer#2-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-1, groupId=group_id] Cluster ID: lkc-3rx3p2
2023-05-18T18:57:54.322+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-1, groupId=group_id] Discovered group coordinator b4-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 2147483643 rack: null)
2023-05-18T18:57:54.324+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] Discovered group coordinator b8-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 2147483639 rack: null)
2023-05-18T18:57:54.365+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-1, groupId=group_id] (Re-)joining group
2023-05-18T18:57:54.365+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-2, groupId=group_id] (Re-)joining group
2023-05-18T18:57:54.365+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-4, groupId=group_id] (Re-)joining group
2023-05-18T18:57:54.365+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] (Re-)joining group
2023-05-18T18:57:54.366+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-5, groupId=group_id3] (Re-)joining group
2023-05-18T18:57:54.390+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] (Re-)joining group
2023-05-18T18:57:54.786+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] Request joining group due to: need to re-join with the given member-id: consumer-group_id3-6-e8f893bd-2dc8-4864-85d6-11c224de1a6e
2023-05-18T18:57:54.786+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-05-18T18:57:54.786+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] (Re-)joining group
2023-05-18T18:57:54.799+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-5, groupId=group_id3] Request joining group due to: need to re-join with the given member-id: consumer-group_id3-5-32253acd-8612-4dcc-87f8-91f5fb93983d
2023-05-18T18:57:54.799+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-5, groupId=group_id3] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-05-18T18:57:54.799+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-5, groupId=group_id3] (Re-)joining group
2023-05-18T18:57:54.832+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Request joining group due to: need to re-join with the given member-id: consumer-group_id2-3-c6511178-f7a9-4810-acef-1b2dd533fe03
2023-05-18T18:57:54.832+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-05-18T18:57:54.832+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] (Re-)joining group
2023-05-18T18:57:54.839+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] Successfully joined group with generation Generation{generationId=70, memberId='consumer-group_id3-6-e8f893bd-2dc8-4864-85d6-11c224de1a6e', protocol='range'}
2023-05-18T18:57:54.841+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] Finished assignment for group at generation 70: {consumer-group_id3-6-e8f893bd-2dc8-4864-85d6-11c224de1a6e=Assignment(partitions=[customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2, customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5])}
2023-05-18T18:57:54.889+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Successfully joined group with generation Generation{generationId=64, memberId='consumer-group_id2-3-c6511178-f7a9-4810-acef-1b2dd533fe03', protocol='range'}
2023-05-18T18:57:54.889+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Finished assignment for group at generation 64: {consumer-group_id2-3-c6511178-f7a9-4810-acef-1b2dd533fe03=Assignment(partitions=[customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2, customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5])}
2023-05-18T18:57:54.894+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] SyncGroup failed: The group began another rebalance. Need to re-join the group. Sent generation was Generation{generationId=70, memberId='consumer-group_id3-6-e8f893bd-2dc8-4864-85d6-11c224de1a6e', protocol='range'}
2023-05-18T18:57:54.894+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] Request joining group due to: rebalance failed due to 'The group is rebalancing, so a rejoin is needed.' (RebalanceInProgressException)
2023-05-18T18:57:54.894+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] (Re-)joining group
2023-05-18T18:57:54.933+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-2, groupId=group_id] Request joining group due to: need to re-join with the given member-id: consumer-group_id-2-fe06b0ab-baa9-416c-b512-daf627830d18
2023-05-18T18:57:54.934+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-2, groupId=group_id] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-05-18T18:57:54.934+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-2, groupId=group_id] (Re-)joining group
2023-05-18T18:57:54.943+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Successfully synced group in generation Generation{generationId=64, memberId='consumer-group_id2-3-c6511178-f7a9-4810-acef-1b2dd533fe03', protocol='range'}
2023-05-18T18:57:54.944+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Notifying assignor about the new Assignment(partitions=[customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2, customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5])
2023-05-18T18:57:54.945+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] Successfully joined group with generation Generation{generationId=71, memberId='consumer-group_id3-6-e8f893bd-2dc8-4864-85d6-11c224de1a6e', protocol='range'}
2023-05-18T18:57:54.946+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] Finished assignment for group at generation 71: {consumer-group_id3-6-e8f893bd-2dc8-4864-85d6-11c224de1a6e=Assignment(partitions=[customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5]), consumer-group_id3-5-32253acd-8612-4dcc-87f8-91f5fb93983d=Assignment(partitions=[customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2])}
2023-05-18T18:57:54.947+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Adding newly assigned partitions: customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2, customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5
2023-05-18T18:57:54.948+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-5, groupId=group_id3] Successfully joined group with generation Generation{generationId=71, memberId='consumer-group_id3-5-32253acd-8612-4dcc-87f8-91f5fb93983d', protocol='range'}
2023-05-18T18:57:54.950+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-1, groupId=group_id] Request joining group due to: need to re-join with the given member-id: consumer-group_id-1-999f07c6-58cc-4599-9d09-117bb6317109
2023-05-18T18:57:54.951+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-1, groupId=group_id] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-05-18T18:57:54.951+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-1, groupId=group_id] (Re-)joining group
2023-05-18T18:57:54.959+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-4, groupId=group_id] Request joining group due to: need to re-join with the given member-id: consumer-group_id-4-551175db-bbe6-4f05-9301-b43e70bba141
2023-05-18T18:57:54.960+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-4, groupId=group_id] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-05-18T18:57:54.960+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-4, groupId=group_id] (Re-)joining group
2023-05-18T18:57:55.012+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Found no committed offset for partition customer_visit_event_backup-3
2023-05-18T18:57:55.012+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Found no committed offset for partition customer_visit_event_backup-4
2023-05-18T18:57:55.012+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Found no committed offset for partition customer_visit_event_backup-5
2023-05-18T18:57:55.012+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Found no committed offset for partition customer_visit_event_backup-0
2023-05-18T18:57:55.012+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Found no committed offset for partition customer_visit_event_backup-1
2023-05-18T18:57:55.015+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Setting offset for partition customer_visit_event_backup-2 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b11-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 11 rack: 2)], epoch=0}}
2023-05-18T18:57:55.027+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-2, groupId=group_id] Successfully joined group with generation Generation{generationId=88, memberId='consumer-group_id-2-fe06b0ab-baa9-416c-b512-daf627830d18', protocol='range'}
2023-05-18T18:57:55.028+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-2, groupId=group_id] Finished assignment for group at generation 88: {consumer-group_id-2-fe06b0ab-baa9-416c-b512-daf627830d18=Assignment(partitions=[customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2, customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5])}
2023-05-18T18:57:55.056+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] Successfully synced group in generation Generation{generationId=71, memberId='consumer-group_id3-6-e8f893bd-2dc8-4864-85d6-11c224de1a6e', protocol='range'}
2023-05-18T18:57:55.056+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] Notifying assignor about the new Assignment(partitions=[customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5])
2023-05-18T18:57:55.057+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] Adding newly assigned partitions: customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5
2023-05-18T18:57:55.066+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-5, groupId=group_id3] Successfully synced group in generation Generation{generationId=71, memberId='consumer-group_id3-5-32253acd-8612-4dcc-87f8-91f5fb93983d', protocol='range'}
2023-05-18T18:57:55.066+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-5, groupId=group_id3] Notifying assignor about the new Assignment(partitions=[customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2])
2023-05-18T18:57:55.066+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-5, groupId=group_id3] Adding newly assigned partitions: customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2
2023-05-18T18:57:55.079+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-2, groupId=group_id] SyncGroup failed: The group began another rebalance. Need to re-join the group. Sent generation was Generation{generationId=88, memberId='consumer-group_id-2-fe06b0ab-baa9-416c-b512-daf627830d18', protocol='range'}
2023-05-18T18:57:55.079+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-2, groupId=group_id] Request joining group due to: rebalance failed due to 'The group is rebalancing, so a rejoin is needed.' (RebalanceInProgressException)
2023-05-18T18:57:55.079+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-2, groupId=group_id] (Re-)joining group
2023-05-18T18:57:55.106+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] Found no committed offset for partition customer_visit_event_backup-3
2023-05-18T18:57:55.106+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] Found no committed offset for partition customer_visit_event_backup-4
2023-05-18T18:57:55.106+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] Found no committed offset for partition customer_visit_event_backup-5
2023-05-18T18:57:55.119+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-5, groupId=group_id3] Found no committed offset for partition customer_visit_event_backup-0
2023-05-18T18:57:55.120+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-5, groupId=group_id3] Found no committed offset for partition customer_visit_event_backup-1
2023-05-18T18:57:55.120+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-5, groupId=group_id3] Setting offset for partition customer_visit_event_backup-2 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b11-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 11 rack: 2)], epoch=0}}
2023-05-18T18:57:55.135+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-2, groupId=group_id] Successfully joined group with generation Generation{generationId=89, memberId='consumer-group_id-2-fe06b0ab-baa9-416c-b512-daf627830d18', protocol='range'}
2023-05-18T18:57:55.135+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-2, groupId=group_id] Finished assignment for group at generation 89: {consumer-group_id-2-fe06b0ab-baa9-416c-b512-daf627830d18=Assignment(partitions=[customer_visit_event_backup-2, customer_visit_event_backup-3]), consumer-group_id-1-999f07c6-58cc-4599-9d09-117bb6317109=Assignment(partitions=[customer_visit_event_backup-0, customer_visit_event_backup-1]), consumer-group_id-4-551175db-bbe6-4f05-9301-b43e70bba141=Assignment(partitions=[customer_visit_event_backup-4, customer_visit_event_backup-5])}
2023-05-18T18:57:55.137+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-4, groupId=group_id] Successfully joined group with generation Generation{generationId=89, memberId='consumer-group_id-4-551175db-bbe6-4f05-9301-b43e70bba141', protocol='range'}
2023-05-18T18:57:55.138+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-1, groupId=group_id] Successfully joined group with generation Generation{generationId=89, memberId='consumer-group_id-1-999f07c6-58cc-4599-9d09-117bb6317109', protocol='range'}
2023-05-18T18:57:55.190+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-2, groupId=group_id] Successfully synced group in generation Generation{generationId=89, memberId='consumer-group_id-2-fe06b0ab-baa9-416c-b512-daf627830d18', protocol='range'}
2023-05-18T18:57:55.190+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-2, groupId=group_id] Notifying assignor about the new Assignment(partitions=[customer_visit_event_backup-2, customer_visit_event_backup-3])
2023-05-18T18:57:55.190+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-2, groupId=group_id] Adding newly assigned partitions: customer_visit_event_backup-2, customer_visit_event_backup-3
2023-05-18T18:57:55.194+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-4, groupId=group_id] Successfully synced group in generation Generation{generationId=89, memberId='consumer-group_id-4-551175db-bbe6-4f05-9301-b43e70bba141', protocol='range'}
2023-05-18T18:57:55.195+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-1, groupId=group_id] Successfully synced group in generation Generation{generationId=89, memberId='consumer-group_id-1-999f07c6-58cc-4599-9d09-117bb6317109', protocol='range'}
2023-05-18T18:57:55.195+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-4, groupId=group_id] Notifying assignor about the new Assignment(partitions=[customer_visit_event_backup-4, customer_visit_event_backup-5])
2023-05-18T18:57:55.195+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-4, groupId=group_id] Adding newly assigned partitions: customer_visit_event_backup-4, customer_visit_event_backup-5
2023-05-18T18:57:55.195+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-1, groupId=group_id] Notifying assignor about the new Assignment(partitions=[customer_visit_event_backup-0, customer_visit_event_backup-1])
2023-05-18T18:57:55.195+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-1, groupId=group_id] Adding newly assigned partitions: customer_visit_event_backup-0, customer_visit_event_backup-1
2023-05-18T18:57:55.251+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-2, groupId=group_id] Found no committed offset for partition customer_visit_event_backup-3
2023-05-18T18:57:55.251+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-2, groupId=group_id] Setting offset for partition customer_visit_event_backup-2 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b11-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 11 rack: 2)], epoch=0}}
2023-05-18T18:57:55.252+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-4, groupId=group_id] Found no committed offset for partition customer_visit_event_backup-4
2023-05-18T18:57:55.252+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-4, groupId=group_id] Found no committed offset for partition customer_visit_event_backup-5
2023-05-18T18:57:55.254+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-1, groupId=group_id] Found no committed offset for partition customer_visit_event_backup-0
2023-05-18T18:57:55.254+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-1, groupId=group_id] Found no committed offset for partition customer_visit_event_backup-1
2023-05-18T18:57:55.634+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] Resetting offset for partition customer_visit_event_backup-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b10-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 10 rack: 1)], epoch=0}}.
2023-05-18T18:57:55.641+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Resetting offset for partition customer_visit_event_backup-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b8-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 8 rack: 2)], epoch=0}}.
2023-05-18T18:57:55.644+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Resetting offset for partition customer_visit_event_backup-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b10-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 10 rack: 1)], epoch=0}}.
2023-05-18T18:57:55.669+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] Resetting offset for partition customer_visit_event_backup-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b8-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 8 rack: 2)], epoch=0}}.
2023-05-18T18:57:55.697+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id-4, groupId=group_id] Resetting offset for partition customer_visit_event_backup-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b8-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 8 rack: 2)], epoch=0}}.
2023-05-18T18:57:55.706+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id3-5, groupId=group_id3] Resetting offset for partition customer_visit_event_backup-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b9-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 9 rack: 0)], epoch=0}}.
2023-05-18T18:57:55.718+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id3-5, groupId=group_id3] Resetting offset for partition customer_visit_event_backup-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b7-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 7 rack: 1)], epoch=0}}.
2023-05-18T18:57:55.719+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id3: partitions assigned: [customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2]
2023-05-18T18:57:55.732+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id-4, groupId=group_id] Resetting offset for partition customer_visit_event_backup-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b10-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 10 rack: 1)], epoch=0}}.
2023-05-18T18:57:55.732+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id: partitions assigned: [customer_visit_event_backup-4, customer_visit_event_backup-5]
2023-05-18T18:57:55.741+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Resetting offset for partition customer_visit_event_backup-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b9-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 9 rack: 0)], epoch=0}}.
2023-05-18T18:57:55.749+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Resetting offset for partition customer_visit_event_backup-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b7-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 7 rack: 1)], epoch=0}}.
2023-05-18T18:57:55.794+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id-1, groupId=group_id] Resetting offset for partition customer_visit_event_backup-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b9-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 9 rack: 0)], epoch=0}}.
2023-05-18T18:57:55.802+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id-1, groupId=group_id] Resetting offset for partition customer_visit_event_backup-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b7-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 7 rack: 1)], epoch=0}}.
2023-05-18T18:57:55.802+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id: partitions assigned: [customer_visit_event_backup-0, customer_visit_event_backup-1]
2023-05-18T18:57:55.807+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] Resetting offset for partition customer_visit_event_backup-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b3-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 3 rack: 0)], epoch=0}}.
2023-05-18T18:57:55.807+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id3: partitions assigned: [customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5]
2023-05-18T18:57:55.814+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Resetting offset for partition customer_visit_event_backup-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b3-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 3 rack: 0)], epoch=0}}.
2023-05-18T18:57:55.814+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id2: partitions assigned: [customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2, customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5]
2023-05-18T18:57:55.853+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id-2, groupId=group_id] Resetting offset for partition customer_visit_event_backup-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b3-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 3 rack: 0)], epoch=0}}.
2023-05-18T18:57:55.853+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id: partitions assigned: [customer_visit_event_backup-2, customer_visit_event_backup-3]
2023-05-18T18:58:06.171+03:00  INFO 8268 --- [nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-05-18T18:58:06.171+03:00  INFO 8268 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
2023-05-18T18:58:06.173+03:00  INFO 8268 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 1 ms
2023-05-18T18:58:09.635+03:00  INFO 8268 --- [nio-8080-exec-1] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [pkc-4nmjv.francecentral.azure.confluent.cloud:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2023-05-18T18:58:09.653+03:00  INFO 8268 --- [nio-8080-exec-1] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-05-18T18:58:09.674+03:00  INFO 8268 --- [nio-8080-exec-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.2
2023-05-18T18:58:09.674+03:00  INFO 8268 --- [nio-8080-exec-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: b66af662e61082cb
2023-05-18T18:58:09.674+03:00  INFO 8268 --- [nio-8080-exec-1] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1684425489674
2023-05-18T18:58:10.147+03:00  INFO 8268 --- [ad | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Resetting the last seen epoch of partition customer_visit_event_backup-0 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:58:10.147+03:00  INFO 8268 --- [ad | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Resetting the last seen epoch of partition customer_visit_event_backup-5 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:58:10.147+03:00  INFO 8268 --- [ad | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Resetting the last seen epoch of partition customer_visit_event_backup-4 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:58:10.147+03:00  INFO 8268 --- [ad | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Resetting the last seen epoch of partition customer_visit_event_backup-1 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:58:10.148+03:00  INFO 8268 --- [ad | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Resetting the last seen epoch of partition customer_visit_event_backup-2 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:58:10.148+03:00  INFO 8268 --- [ad | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Resetting the last seen epoch of partition customer_visit_event_backup-3 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:58:10.148+03:00  INFO 8268 --- [ad | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: lkc-3rx3p2
2023-05-18T18:58:10.148+03:00  INFO 8268 --- [ad | producer-1] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-1] ProducerId set to 9619391 with epoch 0
2023-05-18T18:58:10.770+03:00 ERROR 8268 --- [ntainer#5-0-C-1] o.s.kafka.listener.DefaultErrorHandler   : Backoff FixedBackOff{interval=0, currentAttempts=1, maxAttempts=0} exhausted for customer_visit_event_backup-5@0

org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method could not be invoked with the incoming message
Endpoint handler details:
Method [public void com.aziubin.spring.boot.kafka.KafkaApplication$RestfulController.consumeGroupIdB(java.lang.String) throws java.io.IOException]
Bean [com.aziubin.spring.boot.kafka.KafkaApplication$RestfulController@6dca9bf3]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2988) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2933) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2899) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$58(KafkaMessageListenerContainer.java:2822) ~[spring-kafka-3.0.6.jar:3.0.6]
	at io.micrometer.observation.Observation.observe(Observation.java:562) ~[micrometer-observation-1.10.6.jar:1.10.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2820) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2672) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2558) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2200) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1555) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1519) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1394) ~[spring-kafka-3.0.6.jar:3.0.6]
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1804) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.checkAckArg(MessagingMessageListenerAdapter.java:393) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:371) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2919) ~[spring-kafka-3.0.6.jar:3.0.6]
Caused by: org.springframework.messaging.converter.MessageConversionException: Cannot handle message
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:371) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2919) ~[spring-kafka-3.0.6.jar:3.0.6]
	... 12 common frames omitted
Caused by: org.springframework.messaging.converter.MessageConversionException: Cannot convert from [com.aziubin.spring.boot.kafka.domain.CustomerVisitEvent] to [java.lang.String] for GenericMessage [payload=CustomerVisitEvent(customerId=658fe2f3-1300-4d68-b798-d3270007bef9, dateTime=2023-05-18T18:58:09.618097100), headers={kafka_offset=0, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@51a3e9ff, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=5, kafka_receivedTopic=customer_visit_event_backup, kafka_receivedTimestamp=1684425490148, kafka_groupId=group_id}]
	at org.springframework.messaging.handler.annotation.support.PayloadMethodArgumentResolver.resolveArgument(PayloadMethodArgumentResolver.java:148) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.kafka.annotation.KafkaNullAwarePayloadArgumentResolver.resolveArgument(KafkaNullAwarePayloadArgumentResolver.java:46) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.messaging.handler.invocation.HandlerMethodArgumentResolverComposite.resolveArgument(HandlerMethodArgumentResolverComposite.java:118) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.getMethodArgumentValues(InvocableHandlerMethod.java:147) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:115) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:366) ~[spring-kafka-3.0.6.jar:3.0.6]
	... 15 common frames omitted

2023-05-18T18:58:10.770+03:00 ERROR 8268 --- [ntainer#1-0-C-1] o.s.kafka.listener.DefaultErrorHandler   : Backoff FixedBackOff{interval=0, currentAttempts=1, maxAttempts=0} exhausted for customer_visit_event_backup-5@0

org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method could not be invoked with the incoming message
Endpoint handler details:
Method [public void com.aziubin.spring.boot.kafka.KafkaApplication$RestfulController.consume3(java.lang.String,org.apache.kafka.clients.consumer.ConsumerRecord) throws java.io.IOException]
Bean [com.aziubin.spring.boot.kafka.KafkaApplication$RestfulController@6dca9bf3]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2988) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2933) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2899) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$58(KafkaMessageListenerContainer.java:2822) ~[spring-kafka-3.0.6.jar:3.0.6]
	at io.micrometer.observation.Observation.observe(Observation.java:562) ~[micrometer-observation-1.10.6.jar:1.10.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2820) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2672) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2558) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2200) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1555) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1519) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1394) ~[spring-kafka-3.0.6.jar:3.0.6]
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1804) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.checkAckArg(MessagingMessageListenerAdapter.java:393) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:371) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2919) ~[spring-kafka-3.0.6.jar:3.0.6]
Caused by: org.springframework.messaging.converter.MessageConversionException: Cannot handle message
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:371) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2919) ~[spring-kafka-3.0.6.jar:3.0.6]
	... 12 common frames omitted
Caused by: org.springframework.messaging.converter.MessageConversionException: Cannot convert from [com.aziubin.spring.boot.kafka.domain.CustomerVisitEvent] to [java.lang.String] for GenericMessage [payload=CustomerVisitEvent(customerId=658fe2f3-1300-4d68-b798-d3270007bef9, dateTime=2023-05-18T18:58:09.618097100), headers={kafka_offset=0, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@76041666, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=5, kafka_receivedTopic=customer_visit_event_backup, kafka_receivedTimestamp=1684425490148, kafka_groupId=group_id3}]
	at org.springframework.messaging.handler.annotation.support.PayloadMethodArgumentResolver.resolveArgument(PayloadMethodArgumentResolver.java:148) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.kafka.annotation.KafkaNullAwarePayloadArgumentResolver.resolveArgument(KafkaNullAwarePayloadArgumentResolver.java:46) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.messaging.handler.invocation.HandlerMethodArgumentResolverComposite.resolveArgument(HandlerMethodArgumentResolverComposite.java:118) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.getMethodArgumentValues(InvocableHandlerMethod.java:147) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:115) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:366) ~[spring-kafka-3.0.6.jar:3.0.6]
	... 15 common frames omitted

2023-05-18T18:58:10.771+03:00 ERROR 8268 --- [ntainer#4-0-C-1] o.s.kafka.listener.DefaultErrorHandler   : Backoff FixedBackOff{interval=0, currentAttempts=1, maxAttempts=0} exhausted for customer_visit_event_backup-5@0

org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method could not be invoked with the incoming message
Endpoint handler details:
Method [public void com.aziubin.spring.boot.kafka.KafkaApplication$RestfulController.consume2(java.lang.String,org.apache.kafka.clients.consumer.ConsumerRecord) throws java.io.IOException]
Bean [com.aziubin.spring.boot.kafka.KafkaApplication$RestfulController@6dca9bf3]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2988) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2933) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2899) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$58(KafkaMessageListenerContainer.java:2822) ~[spring-kafka-3.0.6.jar:3.0.6]
	at io.micrometer.observation.Observation.observe(Observation.java:562) ~[micrometer-observation-1.10.6.jar:1.10.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2820) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2672) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2558) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2200) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1555) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1519) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1394) ~[spring-kafka-3.0.6.jar:3.0.6]
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1804) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.checkAckArg(MessagingMessageListenerAdapter.java:393) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:371) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2919) ~[spring-kafka-3.0.6.jar:3.0.6]
Caused by: org.springframework.messaging.converter.MessageConversionException: Cannot handle message
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:371) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2919) ~[spring-kafka-3.0.6.jar:3.0.6]
	... 12 common frames omitted
Caused by: org.springframework.messaging.converter.MessageConversionException: Cannot convert from [com.aziubin.spring.boot.kafka.domain.CustomerVisitEvent] to [java.lang.String] for GenericMessage [payload=CustomerVisitEvent(customerId=658fe2f3-1300-4d68-b798-d3270007bef9, dateTime=2023-05-18T18:58:09.618097100), headers={kafka_offset=0, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@816372c, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=5, kafka_receivedTopic=customer_visit_event_backup, kafka_receivedTimestamp=1684425490148, kafka_groupId=group_id2}]
	at org.springframework.messaging.handler.annotation.support.PayloadMethodArgumentResolver.resolveArgument(PayloadMethodArgumentResolver.java:148) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.kafka.annotation.KafkaNullAwarePayloadArgumentResolver.resolveArgument(KafkaNullAwarePayloadArgumentResolver.java:46) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.messaging.handler.invocation.HandlerMethodArgumentResolverComposite.resolveArgument(HandlerMethodArgumentResolverComposite.java:118) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.getMethodArgumentValues(InvocableHandlerMethod.java:147) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:115) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:366) ~[spring-kafka-3.0.6.jar:3.0.6]
	... 15 common frames omitted

2023-05-18T18:59:47.122+03:00  INFO 8268 --- [   File Watcher] rtingClassPathChangeChangedEventListener : Restarting due to 2 class path changes (0 additions, 0 deletions, 2 modifications)
2023-05-18T18:59:47.130+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-1, groupId=group_id] Revoke previously assigned partitions customer_visit_event_backup-0, customer_visit_event_backup-1
2023-05-18T18:59:47.130+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-2, groupId=group_id] Revoke previously assigned partitions customer_visit_event_backup-2, customer_visit_event_backup-3
2023-05-18T18:59:47.131+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-5, groupId=group_id3] Revoke previously assigned partitions customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2
2023-05-18T18:59:47.131+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id: partitions revoked: [customer_visit_event_backup-2, customer_visit_event_backup-3]
2023-05-18T18:59:47.131+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id: partitions revoked: [customer_visit_event_backup-0, customer_visit_event_backup-1]
2023-05-18T18:59:47.131+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id3: partitions revoked: [customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2]
2023-05-18T18:59:47.131+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-4, groupId=group_id] Revoke previously assigned partitions customer_visit_event_backup-4, customer_visit_event_backup-5
2023-05-18T18:59:47.132+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-2, groupId=group_id] Member consumer-group_id-2-fe06b0ab-baa9-416c-b512-daf627830d18 sending LeaveGroup request to coordinator b4-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 2147483643 rack: null) due to the consumer unsubscribed from all topics
2023-05-18T18:59:47.132+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-5, groupId=group_id3] Member consumer-group_id3-5-32253acd-8612-4dcc-87f8-91f5fb93983d sending LeaveGroup request to coordinator b8-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 2147483639 rack: null) due to the consumer unsubscribed from all topics
2023-05-18T18:59:47.132+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id: partitions revoked: [customer_visit_event_backup-4, customer_visit_event_backup-5]
2023-05-18T18:59:47.133+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-4, groupId=group_id] Member consumer-group_id-4-551175db-bbe6-4f05-9301-b43e70bba141 sending LeaveGroup request to coordinator b4-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 2147483643 rack: null) due to the consumer unsubscribed from all topics
2023-05-18T18:59:47.133+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-1, groupId=group_id] Member consumer-group_id-1-999f07c6-58cc-4599-9d09-117bb6317109 sending LeaveGroup request to coordinator b4-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 2147483643 rack: null) due to the consumer unsubscribed from all topics
2023-05-18T18:59:47.133+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Revoke previously assigned partitions customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2, customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5
2023-05-18T18:59:47.133+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id2: partitions revoked: [customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2, customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5]
2023-05-18T18:59:47.133+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-4, groupId=group_id] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-05-18T18:59:47.133+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-4, groupId=group_id] Request joining group due to: consumer pro-actively leaving the group
2023-05-18T18:59:47.133+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-group_id-4, groupId=group_id] Unsubscribed all topics or patterns and assigned partitions
2023-05-18T18:59:47.133+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-2, groupId=group_id] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-05-18T18:59:47.133+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-2, groupId=group_id] Request joining group due to: consumer pro-actively leaving the group
2023-05-18T18:59:47.133+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-group_id-2, groupId=group_id] Unsubscribed all topics or patterns and assigned partitions
2023-05-18T18:59:47.133+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Member consumer-group_id2-3-c6511178-f7a9-4810-acef-1b2dd533fe03 sending LeaveGroup request to coordinator b0-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2023-05-18T18:59:47.133+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-05-18T18:59:47.133+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Request joining group due to: consumer pro-actively leaving the group
2023-05-18T18:59:47.133+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-5, groupId=group_id3] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-05-18T18:59:47.133+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-1, groupId=group_id] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-05-18T18:59:47.133+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-1, groupId=group_id] Request joining group due to: consumer pro-actively leaving the group
2023-05-18T18:59:47.133+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Unsubscribed all topics or patterns and assigned partitions
2023-05-18T18:59:47.133+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-group_id-1, groupId=group_id] Unsubscribed all topics or patterns and assigned partitions
2023-05-18T18:59:47.133+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-2, groupId=group_id] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-05-18T18:59:47.133+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-5, groupId=group_id3] Request joining group due to: consumer pro-actively leaving the group
2023-05-18T18:59:47.133+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-2, groupId=group_id] Request joining group due to: consumer pro-actively leaving the group
2023-05-18T18:59:47.133+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-group_id3-5, groupId=group_id3] Unsubscribed all topics or patterns and assigned partitions
2023-05-18T18:59:47.133+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-05-18T18:59:47.133+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-3, groupId=group_id2] Request joining group due to: consumer pro-actively leaving the group
2023-05-18T18:59:47.133+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-4, groupId=group_id] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-05-18T18:59:47.133+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-4, groupId=group_id] Request joining group due to: consumer pro-actively leaving the group
2023-05-18T18:59:47.134+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-1, groupId=group_id] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-05-18T18:59:47.134+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-5, groupId=group_id3] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-05-18T18:59:47.134+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-1, groupId=group_id] Request joining group due to: consumer pro-actively leaving the group
2023-05-18T18:59:47.134+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-5, groupId=group_id3] Request joining group due to: consumer pro-actively leaving the group
2023-05-18T18:59:47.135+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] Revoke previously assigned partitions customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5
2023-05-18T18:59:47.135+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id3: partitions revoked: [customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5]
2023-05-18T18:59:47.135+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] Member consumer-group_id3-6-e8f893bd-2dc8-4864-85d6-11c224de1a6e sending LeaveGroup request to coordinator b8-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 2147483639 rack: null) due to the consumer unsubscribed from all topics
2023-05-18T18:59:47.136+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-05-18T18:59:47.136+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] Request joining group due to: consumer pro-actively leaving the group
2023-05-18T18:59:47.136+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] Unsubscribed all topics or patterns and assigned partitions
2023-05-18T18:59:47.137+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-05-18T18:59:47.137+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-6, groupId=group_id3] Request joining group due to: consumer pro-actively leaving the group
2023-05-18T18:59:47.185+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-05-18T18:59:47.185+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-05-18T18:59:47.186+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-05-18T18:59:47.189+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-05-18T18:59:47.189+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-05-18T18:59:47.189+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-05-18T18:59:47.191+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-05-18T18:59:47.191+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-05-18T18:59:47.191+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-05-18T18:59:47.194+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-05-18T18:59:47.194+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-05-18T18:59:47.194+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-05-18T18:59:47.194+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-05-18T18:59:47.194+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-05-18T18:59:47.195+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-05-18T18:59:47.196+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-05-18T18:59:47.196+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-05-18T18:59:47.197+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-05-18T18:59:47.215+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-group_id-2 unregistered
2023-05-18T18:59:47.216+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id: Consumer stopped
2023-05-18T18:59:47.217+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-group_id3-5 unregistered
2023-05-18T18:59:47.217+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id3: Consumer stopped
2023-05-18T18:59:47.218+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-group_id3-6 unregistered
2023-05-18T18:59:47.218+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id3: Consumer stopped
2023-05-18T18:59:47.219+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-group_id2-3 unregistered
2023-05-18T18:59:47.219+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id2: Consumer stopped
2023-05-18T18:59:47.220+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-group_id-4 unregistered
2023-05-18T18:59:47.221+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id: Consumer stopped
2023-05-18T18:59:47.221+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-group_id-1 unregistered
2023-05-18T18:59:47.221+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id: Consumer stopped
2023-05-18T18:59:47.239+03:00  INFO 8268 --- [       Thread-5] o.apache.catalina.core.StandardService   : Stopping service [Tomcat]
2023-05-18T18:59:47.240+03:00  INFO 8268 --- [       Thread-5] o.a.c.c.C.[Tomcat].[localhost].[/]       : Destroying Spring FrameworkServlet 'dispatcherServlet'
2023-05-18T18:59:47.254+03:00  WARN 8268 --- [       Thread-5] o.a.c.loader.WebappClassLoaderBase       : The web application [ROOT] appears to have started a thread named [kafka-producer-network-thread | producer-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/sun.nio.ch.WEPoll.wait(Native Method)
 java.base@17.0.6/sun.nio.ch.WEPollSelectorImpl.doSelect(WEPollSelectorImpl.java:111)
 java.base@17.0.6/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
 java.base@17.0.6/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:141)
 app//org.apache.kafka.common.network.Selector.select(Selector.java:873)
 app//org.apache.kafka.common.network.Selector.poll(Selector.java:465)
 app//org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:560)
 app//org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:328)
 app//org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:243)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-05-18T18:59:47.262+03:00  INFO 8268 --- [       Thread-5] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2023-05-18T18:59:47.268+03:00  INFO 8268 --- [       Thread-5] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-05-18T18:59:47.268+03:00  INFO 8268 --- [       Thread-5] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-05-18T18:59:47.268+03:00  INFO 8268 --- [       Thread-5] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-05-18T18:59:47.268+03:00  INFO 8268 --- [       Thread-5] o.a.kafka.common.utils.AppInfoParser     : App info kafka.producer for producer-1 unregistered

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::                (v3.0.6)

2023-05-18T18:59:47.382+03:00  INFO 8268 --- [  restartedMain] c.a.spring.boot.kafka.KafkaApplication   : Starting KafkaApplication using Java 17.0.6 with PID 8268 (C:\Users\aziub\git\SpringBoot\kafka\target\classes started by aziub in C:\Users\aziub\git\SpringBoot\kafka)
2023-05-18T18:59:47.383+03:00  INFO 8268 --- [  restartedMain] c.a.spring.boot.kafka.KafkaApplication   : No active profile set, falling back to 1 default profile: "default"
2023-05-18T18:59:48.094+03:00  INFO 8268 --- [  restartedMain] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 8080 (http)
2023-05-18T18:59:48.095+03:00  INFO 8268 --- [  restartedMain] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2023-05-18T18:59:48.095+03:00  INFO 8268 --- [  restartedMain] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/10.1.8]
2023-05-18T18:59:48.119+03:00  INFO 8268 --- [  restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2023-05-18T18:59:48.119+03:00  INFO 8268 --- [  restartedMain] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 730 ms
2023-05-18T18:59:48.318+03:00  INFO 8268 --- [  restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : LiveReload server is running on port 35729
2023-05-18T18:59:48.356+03:00  INFO 8268 --- [  restartedMain] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8080 (http) with context path ''
2023-05-18T18:59:48.359+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-4nmjv.francecentral.azure.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_id-7
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-05-18T18:59:48.448+03:00  INFO 8268 --- [  restartedMain] o.a.k.c.s.authenticator.AbstractLogin    : Successfully logged in.
2023-05-18T18:59:48.458+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.2
2023-05-18T18:59:48.458+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: b66af662e61082cb
2023-05-18T18:59:48.458+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1684425588458
2023-05-18T18:59:48.459+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-group_id-7, groupId=group_id] Subscribed to topic(s): customer_visit_event_backup
2023-05-18T18:59:48.462+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-4nmjv.francecentral.azure.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_id-8
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-05-18T18:59:48.470+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.2
2023-05-18T18:59:48.471+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: b66af662e61082cb
2023-05-18T18:59:48.471+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1684425588470
2023-05-18T18:59:48.471+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-group_id-8, groupId=group_id] Subscribed to topic(s): customer_visit_event_backup
2023-05-18T18:59:48.480+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-4nmjv.francecentral.azure.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_id2-9
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-05-18T18:59:48.487+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.2
2023-05-18T18:59:48.487+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: b66af662e61082cb
2023-05-18T18:59:48.487+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1684425588487
2023-05-18T18:59:48.488+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] Subscribed to topic(s): customer_visit_event_backup
2023-05-18T18:59:48.490+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-4nmjv.francecentral.azure.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_id-10
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-05-18T18:59:48.499+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.2
2023-05-18T18:59:48.499+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: b66af662e61082cb
2023-05-18T18:59:48.499+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1684425588499
2023-05-18T18:59:48.500+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-group_id-10, groupId=group_id] Subscribed to topic(s): customer_visit_event_backup
2023-05-18T18:59:48.503+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-4nmjv.francecentral.azure.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_id3-11
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id3
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-05-18T18:59:48.511+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.2
2023-05-18T18:59:48.511+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: b66af662e61082cb
2023-05-18T18:59:48.511+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1684425588511
2023-05-18T18:59:48.512+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-group_id3-11, groupId=group_id3] Subscribed to topic(s): customer_visit_event_backup
2023-05-18T18:59:48.516+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-4nmjv.francecentral.azure.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_id3-12
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id3
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-05-18T18:59:48.523+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.2
2023-05-18T18:59:48.523+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: b66af662e61082cb
2023-05-18T18:59:48.523+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1684425588523
2023-05-18T18:59:48.524+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] Subscribed to topic(s): customer_visit_event_backup
2023-05-18T18:59:48.532+03:00  INFO 8268 --- [  restartedMain] c.a.spring.boot.kafka.KafkaApplication   : Started KafkaApplication in 1.203 seconds (process running for 120.658)
2023-05-18T18:59:48.535+03:00  INFO 8268 --- [  restartedMain] .ConditionEvaluationDeltaLoggingListener : Condition evaluation unchanged
2023-05-18T18:59:49.002+03:00  INFO 8268 --- [ntainer#3-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-8, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-0 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.003+03:00  INFO 8268 --- [ntainer#3-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-8, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-5 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.003+03:00  INFO 8268 --- [ntainer#3-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-8, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-4 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.003+03:00  INFO 8268 --- [ntainer#3-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-8, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-1 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.003+03:00  INFO 8268 --- [ntainer#3-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-8, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-2 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.003+03:00  INFO 8268 --- [ntainer#3-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-8, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-3 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.003+03:00  INFO 8268 --- [ntainer#3-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-8, groupId=group_id] Cluster ID: lkc-3rx3p2
2023-05-18T18:59:49.003+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] Discovered group coordinator b4-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 2147483643 rack: null)
2023-05-18T18:59:49.011+03:00  INFO 8268 --- [ntainer#2-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-7, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-0 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.011+03:00  INFO 8268 --- [ntainer#2-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-7, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-5 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.011+03:00  INFO 8268 --- [ntainer#2-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-7, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-4 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.011+03:00  INFO 8268 --- [ntainer#2-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-7, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-1 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.012+03:00  INFO 8268 --- [ntainer#2-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-7, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-2 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.012+03:00  INFO 8268 --- [ntainer#2-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-7, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-3 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.012+03:00  INFO 8268 --- [ntainer#2-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-7, groupId=group_id] Cluster ID: lkc-3rx3p2
2023-05-18T18:59:49.012+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-7, groupId=group_id] Discovered group coordinator b4-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 2147483643 rack: null)
2023-05-18T18:59:49.045+03:00  INFO 8268 --- [ntainer#4-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] Resetting the last seen epoch of partition customer_visit_event_backup-0 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.045+03:00  INFO 8268 --- [ntainer#4-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] Resetting the last seen epoch of partition customer_visit_event_backup-5 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.046+03:00  INFO 8268 --- [ntainer#4-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] Resetting the last seen epoch of partition customer_visit_event_backup-4 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.046+03:00  INFO 8268 --- [ntainer#4-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] Resetting the last seen epoch of partition customer_visit_event_backup-1 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.046+03:00  INFO 8268 --- [ntainer#4-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] Resetting the last seen epoch of partition customer_visit_event_backup-2 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.046+03:00  INFO 8268 --- [ntainer#4-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] Resetting the last seen epoch of partition customer_visit_event_backup-3 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.046+03:00  INFO 8268 --- [ntainer#4-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] Cluster ID: lkc-3rx3p2
2023-05-18T18:59:49.046+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] Discovered group coordinator b0-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 2147483647 rack: null)
2023-05-18T18:59:49.065+03:00  INFO 8268 --- [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-11, groupId=group_id3] Resetting the last seen epoch of partition customer_visit_event_backup-0 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.066+03:00  INFO 8268 --- [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-11, groupId=group_id3] Resetting the last seen epoch of partition customer_visit_event_backup-5 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.066+03:00  INFO 8268 --- [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-11, groupId=group_id3] Resetting the last seen epoch of partition customer_visit_event_backup-4 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.066+03:00  INFO 8268 --- [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-11, groupId=group_id3] Resetting the last seen epoch of partition customer_visit_event_backup-1 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.066+03:00  INFO 8268 --- [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-11, groupId=group_id3] Resetting the last seen epoch of partition customer_visit_event_backup-2 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.066+03:00  INFO 8268 --- [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-11, groupId=group_id3] Resetting the last seen epoch of partition customer_visit_event_backup-3 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.066+03:00  INFO 8268 --- [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-11, groupId=group_id3] Cluster ID: lkc-3rx3p2
2023-05-18T18:59:49.191+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-11, groupId=group_id3] Discovered group coordinator b8-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 2147483639 rack: null)
2023-05-18T18:59:49.066+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] (Re-)joining group
2023-05-18T18:59:49.068+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] (Re-)joining group
2023-05-18T18:59:49.070+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-7, groupId=group_id] (Re-)joining group
2023-05-18T18:59:49.162+03:00  INFO 8268 --- [ntainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] Resetting the last seen epoch of partition customer_visit_event_backup-0 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.213+03:00  INFO 8268 --- [ntainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] Resetting the last seen epoch of partition customer_visit_event_backup-5 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.213+03:00  INFO 8268 --- [ntainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] Resetting the last seen epoch of partition customer_visit_event_backup-4 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.213+03:00  INFO 8268 --- [ntainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] Resetting the last seen epoch of partition customer_visit_event_backup-1 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.213+03:00  INFO 8268 --- [ntainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] Resetting the last seen epoch of partition customer_visit_event_backup-2 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.213+03:00  INFO 8268 --- [ntainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] Resetting the last seen epoch of partition customer_visit_event_backup-3 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.214+03:00  INFO 8268 --- [ntainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] Cluster ID: lkc-3rx3p2
2023-05-18T18:59:49.215+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] Discovered group coordinator b8-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 2147483639 rack: null)
2023-05-18T18:59:49.279+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-11, groupId=group_id3] (Re-)joining group
2023-05-18T18:59:49.281+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] (Re-)joining group
2023-05-18T18:59:49.309+03:00  INFO 8268 --- [ntainer#5-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-10, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-0 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.309+03:00  INFO 8268 --- [ntainer#5-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-10, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-5 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.309+03:00  INFO 8268 --- [ntainer#5-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-10, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-4 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.309+03:00  INFO 8268 --- [ntainer#5-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-10, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-1 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.309+03:00  INFO 8268 --- [ntainer#5-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-10, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-2 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.309+03:00  INFO 8268 --- [ntainer#5-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-10, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-3 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:49.310+03:00  INFO 8268 --- [ntainer#5-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-10, groupId=group_id] Cluster ID: lkc-3rx3p2
2023-05-18T18:59:49.310+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-10, groupId=group_id] Discovered group coordinator b4-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 2147483643 rack: null)
2023-05-18T18:59:49.311+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-10, groupId=group_id] (Re-)joining group
2023-05-18T18:59:49.605+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] Request joining group due to: need to re-join with the given member-id: consumer-group_id-8-2cd984dc-ee12-40c0-a718-14f988e6f821
2023-05-18T18:59:49.605+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-05-18T18:59:49.605+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] (Re-)joining group
2023-05-18T18:59:49.620+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] Request joining group due to: need to re-join with the given member-id: consumer-group_id2-9-38fa465b-7245-42d8-a39e-cf3b2f5fadc9
2023-05-18T18:59:49.620+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-05-18T18:59:49.620+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] (Re-)joining group
2023-05-18T18:59:49.623+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-7, groupId=group_id] Request joining group due to: need to re-join with the given member-id: consumer-group_id-7-619b3ee0-e960-46e0-9f40-d97eeeac4144
2023-05-18T18:59:49.623+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-7, groupId=group_id] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-05-18T18:59:49.623+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-7, groupId=group_id] (Re-)joining group
2023-05-18T18:59:49.661+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] Successfully joined group with generation Generation{generationId=91, memberId='consumer-group_id-8-2cd984dc-ee12-40c0-a718-14f988e6f821', protocol='range'}
2023-05-18T18:59:49.661+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] Finished assignment for group at generation 91: {consumer-group_id-8-2cd984dc-ee12-40c0-a718-14f988e6f821=Assignment(partitions=[customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2, customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5])}
2023-05-18T18:59:49.673+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] Successfully joined group with generation Generation{generationId=66, memberId='consumer-group_id2-9-38fa465b-7245-42d8-a39e-cf3b2f5fadc9', protocol='range'}
2023-05-18T18:59:49.673+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] Finished assignment for group at generation 66: {consumer-group_id2-9-38fa465b-7245-42d8-a39e-cf3b2f5fadc9=Assignment(partitions=[customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2, customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5])}
2023-05-18T18:59:49.712+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] SyncGroup failed: The group began another rebalance. Need to re-join the group. Sent generation was Generation{generationId=91, memberId='consumer-group_id-8-2cd984dc-ee12-40c0-a718-14f988e6f821', protocol='range'}
2023-05-18T18:59:49.761+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] Successfully synced group in generation Generation{generationId=66, memberId='consumer-group_id2-9-38fa465b-7245-42d8-a39e-cf3b2f5fadc9', protocol='range'}
2023-05-18T18:59:49.797+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] Notifying assignor about the new Assignment(partitions=[customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2, customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5])
2023-05-18T18:59:49.798+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] Adding newly assigned partitions: customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2, customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5
2023-05-18T18:59:49.799+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] Request joining group due to: rebalance failed due to 'The group is rebalancing, so a rejoin is needed.' (RebalanceInProgressException)
2023-05-18T18:59:49.800+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] (Re-)joining group
2023-05-18T18:59:49.849+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] Found no committed offset for partition customer_visit_event_backup-3
2023-05-18T18:59:49.849+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] Found no committed offset for partition customer_visit_event_backup-4
2023-05-18T18:59:49.849+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] Found no committed offset for partition customer_visit_event_backup-0
2023-05-18T18:59:49.849+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] Found no committed offset for partition customer_visit_event_backup-1
2023-05-18T18:59:49.850+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] Setting offset for partition customer_visit_event_backup-2 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b11-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 11 rack: 2)], epoch=0}}
2023-05-18T18:59:49.850+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] Setting offset for partition customer_visit_event_backup-5 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b8-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 8 rack: 2)], epoch=0}}
2023-05-18T18:59:49.852+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] Successfully joined group with generation Generation{generationId=92, memberId='consumer-group_id-8-2cd984dc-ee12-40c0-a718-14f988e6f821', protocol='range'}
2023-05-18T18:59:49.853+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] Finished assignment for group at generation 92: {consumer-group_id-8-2cd984dc-ee12-40c0-a718-14f988e6f821=Assignment(partitions=[customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5]), consumer-group_id-7-619b3ee0-e960-46e0-9f40-d97eeeac4144=Assignment(partitions=[customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2])}
2023-05-18T18:59:49.853+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-7, groupId=group_id] Successfully joined group with generation Generation{generationId=92, memberId='consumer-group_id-7-619b3ee0-e960-46e0-9f40-d97eeeac4144', protocol='range'}
2023-05-18T18:59:49.870+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] Request joining group due to: need to re-join with the given member-id: consumer-group_id3-12-43a76d57-9a77-4fc8-a30c-3ad987e62ef0
2023-05-18T18:59:49.872+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-05-18T18:59:49.872+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] (Re-)joining group
2023-05-18T18:59:49.909+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-11, groupId=group_id3] Request joining group due to: need to re-join with the given member-id: consumer-group_id3-11-e8463e1a-5e49-40ca-b5c2-23e3df7b5882
2023-05-18T18:59:49.909+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-11, groupId=group_id3] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-05-18T18:59:49.909+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-11, groupId=group_id3] (Re-)joining group
2023-05-18T18:59:49.914+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-7, groupId=group_id] Successfully synced group in generation Generation{generationId=92, memberId='consumer-group_id-7-619b3ee0-e960-46e0-9f40-d97eeeac4144', protocol='range'}
2023-05-18T18:59:49.915+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-7, groupId=group_id] Notifying assignor about the new Assignment(partitions=[customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2])
2023-05-18T18:59:49.915+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-7, groupId=group_id] Adding newly assigned partitions: customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2
2023-05-18T18:59:49.918+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] Successfully synced group in generation Generation{generationId=92, memberId='consumer-group_id-8-2cd984dc-ee12-40c0-a718-14f988e6f821', protocol='range'}
2023-05-18T18:59:49.918+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] Notifying assignor about the new Assignment(partitions=[customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5])
2023-05-18T18:59:49.918+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] Adding newly assigned partitions: customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5
2023-05-18T18:59:49.933+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] Successfully joined group with generation Generation{generationId=73, memberId='consumer-group_id3-12-43a76d57-9a77-4fc8-a30c-3ad987e62ef0', protocol='range'}
2023-05-18T18:59:49.933+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] Finished assignment for group at generation 73: {consumer-group_id3-12-43a76d57-9a77-4fc8-a30c-3ad987e62ef0=Assignment(partitions=[customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2, customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5])}
2023-05-18T18:59:49.970+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-7, groupId=group_id] Found no committed offset for partition customer_visit_event_backup-0
2023-05-18T18:59:49.970+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-7, groupId=group_id] Found no committed offset for partition customer_visit_event_backup-1
2023-05-18T18:59:49.970+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-7, groupId=group_id] Setting offset for partition customer_visit_event_backup-2 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b11-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 11 rack: 2)], epoch=0}}
2023-05-18T18:59:49.975+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] Found no committed offset for partition customer_visit_event_backup-3
2023-05-18T18:59:49.975+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] Found no committed offset for partition customer_visit_event_backup-4
2023-05-18T18:59:49.975+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] Setting offset for partition customer_visit_event_backup-5 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b8-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 8 rack: 2)], epoch=0}}
2023-05-18T18:59:49.990+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] SyncGroup failed: The group began another rebalance. Need to re-join the group. Sent generation was Generation{generationId=73, memberId='consumer-group_id3-12-43a76d57-9a77-4fc8-a30c-3ad987e62ef0', protocol='range'}
2023-05-18T18:59:49.990+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] Request joining group due to: rebalance failed due to 'The group is rebalancing, so a rejoin is needed.' (RebalanceInProgressException)
2023-05-18T18:59:49.991+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] (Re-)joining group
2023-05-18T18:59:50.044+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] Successfully joined group with generation Generation{generationId=74, memberId='consumer-group_id3-12-43a76d57-9a77-4fc8-a30c-3ad987e62ef0', protocol='range'}
2023-05-18T18:59:50.045+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-11, groupId=group_id3] Successfully joined group with generation Generation{generationId=74, memberId='consumer-group_id3-11-e8463e1a-5e49-40ca-b5c2-23e3df7b5882', protocol='range'}
2023-05-18T18:59:50.045+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] Finished assignment for group at generation 74: {consumer-group_id3-11-e8463e1a-5e49-40ca-b5c2-23e3df7b5882=Assignment(partitions=[customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2]), consumer-group_id3-12-43a76d57-9a77-4fc8-a30c-3ad987e62ef0=Assignment(partitions=[customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5])}
2023-05-18T18:59:50.102+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] Successfully synced group in generation Generation{generationId=74, memberId='consumer-group_id3-12-43a76d57-9a77-4fc8-a30c-3ad987e62ef0', protocol='range'}
2023-05-18T18:59:50.102+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] Notifying assignor about the new Assignment(partitions=[customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5])
2023-05-18T18:59:50.102+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] Adding newly assigned partitions: customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5
2023-05-18T18:59:50.104+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-11, groupId=group_id3] Successfully synced group in generation Generation{generationId=74, memberId='consumer-group_id3-11-e8463e1a-5e49-40ca-b5c2-23e3df7b5882', protocol='range'}
2023-05-18T18:59:50.104+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-11, groupId=group_id3] Notifying assignor about the new Assignment(partitions=[customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2])
2023-05-18T18:59:50.104+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-11, groupId=group_id3] Adding newly assigned partitions: customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2
2023-05-18T18:59:50.159+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] Found no committed offset for partition customer_visit_event_backup-3
2023-05-18T18:59:50.159+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] Found no committed offset for partition customer_visit_event_backup-4
2023-05-18T18:59:50.159+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] Setting offset for partition customer_visit_event_backup-5 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b8-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 8 rack: 2)], epoch=0}}
2023-05-18T18:59:50.164+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-11, groupId=group_id3] Found no committed offset for partition customer_visit_event_backup-0
2023-05-18T18:59:50.164+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-11, groupId=group_id3] Found no committed offset for partition customer_visit_event_backup-1
2023-05-18T18:59:50.164+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-11, groupId=group_id3] Setting offset for partition customer_visit_event_backup-2 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b11-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 11 rack: 2)], epoch=0}}
2023-05-18T18:59:50.416+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id-7, groupId=group_id] Resetting offset for partition customer_visit_event_backup-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b9-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 9 rack: 0)], epoch=0}}.
2023-05-18T18:59:50.457+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id-8, groupId=group_id] Resetting offset for partition customer_visit_event_backup-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b10-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 10 rack: 1)], epoch=0}}.
2023-05-18T18:59:50.472+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] Resetting offset for partition customer_visit_event_backup-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b10-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 10 rack: 1)], epoch=0}}.
2023-05-18T18:59:50.490+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] Resetting offset for partition customer_visit_event_backup-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b9-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 9 rack: 0)], epoch=0}}.
2023-05-18T18:59:50.508+03:00  INFO 8268 --- [nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-05-18T18:59:50.508+03:00  INFO 8268 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
2023-05-18T18:59:50.509+03:00  INFO 8268 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 1 ms
2023-05-18T18:59:50.547+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id-7, groupId=group_id] Resetting offset for partition customer_visit_event_backup-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b7-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 7 rack: 1)], epoch=0}}.
2023-05-18T18:59:50.548+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id: partitions assigned: [customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2]
2023-05-18T18:59:50.624+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] Resetting offset for partition customer_visit_event_backup-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b10-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 10 rack: 1)], epoch=0}}.
2023-05-18T18:59:50.629+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id3-11, groupId=group_id3] Resetting offset for partition customer_visit_event_backup-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b9-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 9 rack: 0)], epoch=0}}.
2023-05-18T18:59:50.629+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] Resetting offset for partition customer_visit_event_backup-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b7-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 7 rack: 1)], epoch=0}}.
2023-05-18T18:59:50.645+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] Resetting offset for partition customer_visit_event_backup-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b3-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 3 rack: 0)], epoch=0}}.
2023-05-18T18:59:50.645+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id-8, groupId=group_id] Resetting offset for partition customer_visit_event_backup-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b3-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 3 rack: 0)], epoch=0}}.
2023-05-18T18:59:50.645+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id2: partitions assigned: [customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2, customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5]
2023-05-18T18:59:50.645+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id: partitions assigned: [customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5]
2023-05-18T18:59:50.647+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id3-11, groupId=group_id3] Resetting offset for partition customer_visit_event_backup-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b7-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 7 rack: 1)], epoch=0}}.
2023-05-18T18:59:50.647+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id3: partitions assigned: [customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2]
2023-05-18T18:59:50.776+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] Resetting offset for partition customer_visit_event_backup-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b3-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 3 rack: 0)], epoch=0}}.
2023-05-18T18:59:50.777+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id3: partitions assigned: [customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5]
2023-05-18T18:59:50.784+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-10, groupId=group_id] Request joining group due to: need to re-join with the given member-id: consumer-group_id-10-59abfd68-f379-4f71-b044-a1a587d7984d
2023-05-18T18:59:50.784+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-10, groupId=group_id] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-05-18T18:59:50.784+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-10, groupId=group_id] (Re-)joining group
2023-05-18T18:59:52.908+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] Request joining group due to: group is already rebalancing
2023-05-18T18:59:52.910+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] Revoke previously assigned partitions customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5
2023-05-18T18:59:52.910+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id: partitions revoked: [customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5]
2023-05-18T18:59:52.910+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] (Re-)joining group
2023-05-18T18:59:52.911+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-7, groupId=group_id] Request joining group due to: group is already rebalancing
2023-05-18T18:59:52.911+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-7, groupId=group_id] Revoke previously assigned partitions customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2
2023-05-18T18:59:52.911+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id: partitions revoked: [customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2]
2023-05-18T18:59:52.911+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-7, groupId=group_id] (Re-)joining group
2023-05-18T18:59:52.969+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-10, groupId=group_id] Successfully joined group with generation Generation{generationId=93, memberId='consumer-group_id-10-59abfd68-f379-4f71-b044-a1a587d7984d', protocol='range'}
2023-05-18T18:59:52.969+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] Successfully joined group with generation Generation{generationId=93, memberId='consumer-group_id-8-2cd984dc-ee12-40c0-a718-14f988e6f821', protocol='range'}
2023-05-18T18:59:52.970+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] Finished assignment for group at generation 93: {consumer-group_id-8-2cd984dc-ee12-40c0-a718-14f988e6f821=Assignment(partitions=[customer_visit_event_backup-4, customer_visit_event_backup-5]), consumer-group_id-7-619b3ee0-e960-46e0-9f40-d97eeeac4144=Assignment(partitions=[customer_visit_event_backup-2, customer_visit_event_backup-3]), consumer-group_id-10-59abfd68-f379-4f71-b044-a1a587d7984d=Assignment(partitions=[customer_visit_event_backup-0, customer_visit_event_backup-1])}
2023-05-18T18:59:52.971+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-7, groupId=group_id] Successfully joined group with generation Generation{generationId=93, memberId='consumer-group_id-7-619b3ee0-e960-46e0-9f40-d97eeeac4144', protocol='range'}
2023-05-18T18:59:52.988+03:00  INFO 8268 --- [nio-8080-exec-1] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [pkc-4nmjv.francecentral.azure.confluent.cloud:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2023-05-18T18:59:52.990+03:00  INFO 8268 --- [nio-8080-exec-1] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-2] Instantiated an idempotent producer.
2023-05-18T18:59:52.997+03:00  INFO 8268 --- [nio-8080-exec-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.2
2023-05-18T18:59:52.997+03:00  INFO 8268 --- [nio-8080-exec-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: b66af662e61082cb
2023-05-18T18:59:52.997+03:00  INFO 8268 --- [nio-8080-exec-1] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1684425592997
2023-05-18T18:59:53.025+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-10, groupId=group_id] Successfully synced group in generation Generation{generationId=93, memberId='consumer-group_id-10-59abfd68-f379-4f71-b044-a1a587d7984d', protocol='range'}
2023-05-18T18:59:53.025+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-10, groupId=group_id] Notifying assignor about the new Assignment(partitions=[customer_visit_event_backup-0, customer_visit_event_backup-1])
2023-05-18T18:59:53.025+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-10, groupId=group_id] Adding newly assigned partitions: customer_visit_event_backup-0, customer_visit_event_backup-1
2023-05-18T18:59:53.026+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] Successfully synced group in generation Generation{generationId=93, memberId='consumer-group_id-8-2cd984dc-ee12-40c0-a718-14f988e6f821', protocol='range'}
2023-05-18T18:59:53.026+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] Notifying assignor about the new Assignment(partitions=[customer_visit_event_backup-4, customer_visit_event_backup-5])
2023-05-18T18:59:53.026+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] Adding newly assigned partitions: customer_visit_event_backup-4, customer_visit_event_backup-5
2023-05-18T18:59:53.028+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-7, groupId=group_id] Successfully synced group in generation Generation{generationId=93, memberId='consumer-group_id-7-619b3ee0-e960-46e0-9f40-d97eeeac4144', protocol='range'}
2023-05-18T18:59:53.028+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-7, groupId=group_id] Notifying assignor about the new Assignment(partitions=[customer_visit_event_backup-2, customer_visit_event_backup-3])
2023-05-18T18:59:53.028+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-7, groupId=group_id] Adding newly assigned partitions: customer_visit_event_backup-2, customer_visit_event_backup-3
2023-05-18T18:59:53.076+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] Found no committed offset for partition customer_visit_event_backup-4
2023-05-18T18:59:53.077+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] Setting offset for partition customer_visit_event_backup-5 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b8-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 8 rack: 2)], epoch=0}}
2023-05-18T18:59:53.077+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-10, groupId=group_id] Found no committed offset for partition customer_visit_event_backup-0
2023-05-18T18:59:53.077+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-10, groupId=group_id] Found no committed offset for partition customer_visit_event_backup-1
2023-05-18T18:59:53.084+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-7, groupId=group_id] Found no committed offset for partition customer_visit_event_backup-3
2023-05-18T18:59:53.085+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-7, groupId=group_id] Setting offset for partition customer_visit_event_backup-2 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b11-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 11 rack: 2)], epoch=0}}
2023-05-18T18:59:53.420+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id-8, groupId=group_id] Resetting offset for partition customer_visit_event_backup-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b10-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 10 rack: 1)], epoch=0}}.
2023-05-18T18:59:53.420+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id: partitions assigned: [customer_visit_event_backup-4, customer_visit_event_backup-5]
2023-05-18T18:59:53.453+03:00  INFO 8268 --- [ad | producer-2] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-2] Resetting the last seen epoch of partition customer_visit_event_backup-0 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:53.453+03:00  INFO 8268 --- [ad | producer-2] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-2] Resetting the last seen epoch of partition customer_visit_event_backup-5 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:53.453+03:00  INFO 8268 --- [ad | producer-2] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-2] Resetting the last seen epoch of partition customer_visit_event_backup-4 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:53.453+03:00  INFO 8268 --- [ad | producer-2] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-2] Resetting the last seen epoch of partition customer_visit_event_backup-1 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:53.453+03:00  INFO 8268 --- [ad | producer-2] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-2] Resetting the last seen epoch of partition customer_visit_event_backup-2 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:53.453+03:00  INFO 8268 --- [ad | producer-2] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-2] Resetting the last seen epoch of partition customer_visit_event_backup-3 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T18:59:53.453+03:00  INFO 8268 --- [ad | producer-2] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-2] Cluster ID: lkc-3rx3p2
2023-05-18T18:59:53.453+03:00  INFO 8268 --- [ad | producer-2] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-2] ProducerId set to 9611668 with epoch 0
2023-05-18T18:59:53.514+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id-10, groupId=group_id] Resetting offset for partition customer_visit_event_backup-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b9-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 9 rack: 0)], epoch=0}}.
2023-05-18T18:59:53.514+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id-10, groupId=group_id] Resetting offset for partition customer_visit_event_backup-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b7-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 7 rack: 1)], epoch=0}}.
2023-05-18T18:59:53.514+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id: partitions assigned: [customer_visit_event_backup-0, customer_visit_event_backup-1]
2023-05-18T18:59:53.536+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id-7, groupId=group_id] Resetting offset for partition customer_visit_event_backup-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b3-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 3 rack: 0)], epoch=0}}.
2023-05-18T18:59:53.537+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id: partitions assigned: [customer_visit_event_backup-2, customer_visit_event_backup-3]
2023-05-18T18:59:53.897+03:00 ERROR 8268 --- [ntainer#4-0-C-1] o.s.kafka.listener.DefaultErrorHandler   : Backoff FixedBackOff{interval=0, currentAttempts=1, maxAttempts=0} exhausted for customer_visit_event_backup-5@1

org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method could not be invoked with the incoming message
Endpoint handler details:
Method [public void com.aziubin.spring.boot.kafka.KafkaApplication$RestfulController.consume2(java.lang.String,org.apache.kafka.clients.consumer.ConsumerRecord) throws java.io.IOException]
Bean [com.aziubin.spring.boot.kafka.KafkaApplication$RestfulController@1daa99aa]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2988) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2933) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2899) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$58(KafkaMessageListenerContainer.java:2822) ~[spring-kafka-3.0.6.jar:3.0.6]
	at io.micrometer.observation.Observation.observe(Observation.java:562) ~[micrometer-observation-1.10.6.jar:1.10.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2820) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2672) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2558) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2200) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1555) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1519) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1394) ~[spring-kafka-3.0.6.jar:3.0.6]
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1804) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.checkAckArg(MessagingMessageListenerAdapter.java:393) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:371) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2919) ~[spring-kafka-3.0.6.jar:3.0.6]
Caused by: org.springframework.messaging.converter.MessageConversionException: Cannot handle message
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:371) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2919) ~[spring-kafka-3.0.6.jar:3.0.6]
	... 12 common frames omitted
Caused by: org.springframework.messaging.converter.MessageConversionException: Cannot convert from [com.aziubin.spring.boot.kafka.domain.CustomerVisitEvent] to [java.lang.String] for GenericMessage [payload=CustomerVisitEvent(customerId=ecfcf538-2d59-4565-96cc-3aa66ff5ad0a, dateTime=2023-05-18T18:59:52.986241), headers={kafka_offset=1, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@6e28d33a, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=5, kafka_receivedTopic=customer_visit_event_backup, kafka_receivedTimestamp=1684425593453, kafka_groupId=group_id2}]
	at org.springframework.messaging.handler.annotation.support.PayloadMethodArgumentResolver.resolveArgument(PayloadMethodArgumentResolver.java:148) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.kafka.annotation.KafkaNullAwarePayloadArgumentResolver.resolveArgument(KafkaNullAwarePayloadArgumentResolver.java:46) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.messaging.handler.invocation.HandlerMethodArgumentResolverComposite.resolveArgument(HandlerMethodArgumentResolverComposite.java:118) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.getMethodArgumentValues(InvocableHandlerMethod.java:147) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:115) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:366) ~[spring-kafka-3.0.6.jar:3.0.6]
	... 15 common frames omitted

2023-05-18T18:59:53.896+03:00 ERROR 8268 --- [ntainer#1-0-C-1] o.s.kafka.listener.DefaultErrorHandler   : Backoff FixedBackOff{interval=0, currentAttempts=1, maxAttempts=0} exhausted for customer_visit_event_backup-5@1

org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method could not be invoked with the incoming message
Endpoint handler details:
Method [public void com.aziubin.spring.boot.kafka.KafkaApplication$RestfulController.consume3(java.lang.String,org.apache.kafka.clients.consumer.ConsumerRecord) throws java.io.IOException]
Bean [com.aziubin.spring.boot.kafka.KafkaApplication$RestfulController@1daa99aa]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2988) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2933) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2899) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$58(KafkaMessageListenerContainer.java:2822) ~[spring-kafka-3.0.6.jar:3.0.6]
	at io.micrometer.observation.Observation.observe(Observation.java:562) ~[micrometer-observation-1.10.6.jar:1.10.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2820) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2672) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2558) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2200) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1555) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1519) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1394) ~[spring-kafka-3.0.6.jar:3.0.6]
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1804) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.checkAckArg(MessagingMessageListenerAdapter.java:393) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:371) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2919) ~[spring-kafka-3.0.6.jar:3.0.6]
Caused by: org.springframework.messaging.converter.MessageConversionException: Cannot handle message
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:371) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2919) ~[spring-kafka-3.0.6.jar:3.0.6]
	... 12 common frames omitted
Caused by: org.springframework.messaging.converter.MessageConversionException: Cannot convert from [com.aziubin.spring.boot.kafka.domain.CustomerVisitEvent] to [java.lang.String] for GenericMessage [payload=CustomerVisitEvent(customerId=ecfcf538-2d59-4565-96cc-3aa66ff5ad0a, dateTime=2023-05-18T18:59:52.986241), headers={kafka_offset=1, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@671468b, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=5, kafka_receivedTopic=customer_visit_event_backup, kafka_receivedTimestamp=1684425593453, kafka_groupId=group_id3}]
	at org.springframework.messaging.handler.annotation.support.PayloadMethodArgumentResolver.resolveArgument(PayloadMethodArgumentResolver.java:148) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.kafka.annotation.KafkaNullAwarePayloadArgumentResolver.resolveArgument(KafkaNullAwarePayloadArgumentResolver.java:46) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.messaging.handler.invocation.HandlerMethodArgumentResolverComposite.resolveArgument(HandlerMethodArgumentResolverComposite.java:118) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.getMethodArgumentValues(InvocableHandlerMethod.java:147) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:115) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:366) ~[spring-kafka-3.0.6.jar:3.0.6]
	... 15 common frames omitted

2023-05-18T18:59:53.901+03:00 ERROR 8268 --- [ntainer#3-0-C-1] o.s.kafka.listener.DefaultErrorHandler   : Backoff FixedBackOff{interval=0, currentAttempts=1, maxAttempts=0} exhausted for customer_visit_event_backup-5@1

org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method could not be invoked with the incoming message
Endpoint handler details:
Method [public void com.aziubin.spring.boot.kafka.KafkaApplication$RestfulController.consumeGroupIdA(java.lang.String) throws java.io.IOException]
Bean [com.aziubin.spring.boot.kafka.KafkaApplication$RestfulController@1daa99aa]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2988) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2933) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2899) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$58(KafkaMessageListenerContainer.java:2822) ~[spring-kafka-3.0.6.jar:3.0.6]
	at io.micrometer.observation.Observation.observe(Observation.java:562) ~[micrometer-observation-1.10.6.jar:1.10.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2820) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2672) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2558) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2200) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1555) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1519) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1394) ~[spring-kafka-3.0.6.jar:3.0.6]
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1804) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.checkAckArg(MessagingMessageListenerAdapter.java:393) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:371) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2919) ~[spring-kafka-3.0.6.jar:3.0.6]
Caused by: org.springframework.messaging.converter.MessageConversionException: Cannot handle message
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:371) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2919) ~[spring-kafka-3.0.6.jar:3.0.6]
	... 12 common frames omitted
Caused by: org.springframework.messaging.converter.MessageConversionException: Cannot convert from [com.aziubin.spring.boot.kafka.domain.CustomerVisitEvent] to [java.lang.String] for GenericMessage [payload=CustomerVisitEvent(customerId=ecfcf538-2d59-4565-96cc-3aa66ff5ad0a, dateTime=2023-05-18T18:59:52.986241), headers={kafka_offset=1, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@30ccc4c4, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=5, kafka_receivedTopic=customer_visit_event_backup, kafka_receivedTimestamp=1684425593453, kafka_groupId=group_id}]
	at org.springframework.messaging.handler.annotation.support.PayloadMethodArgumentResolver.resolveArgument(PayloadMethodArgumentResolver.java:148) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.kafka.annotation.KafkaNullAwarePayloadArgumentResolver.resolveArgument(KafkaNullAwarePayloadArgumentResolver.java:46) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.messaging.handler.invocation.HandlerMethodArgumentResolverComposite.resolveArgument(HandlerMethodArgumentResolverComposite.java:118) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.getMethodArgumentValues(InvocableHandlerMethod.java:147) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:115) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:366) ~[spring-kafka-3.0.6.jar:3.0.6]
	... 15 common frames omitted

2023-05-18T19:00:38.142+03:00  INFO 8268 --- [   File Watcher] rtingClassPathChangeChangedEventListener : Restarting due to 2 class path changes (0 additions, 0 deletions, 2 modifications)
2023-05-18T19:00:38.143+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-7, groupId=group_id] Revoke previously assigned partitions customer_visit_event_backup-2, customer_visit_event_backup-3
2023-05-18T19:00:38.143+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-11, groupId=group_id3] Revoke previously assigned partitions customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2
2023-05-18T19:00:38.143+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] Revoke previously assigned partitions customer_visit_event_backup-4, customer_visit_event_backup-5
2023-05-18T19:00:38.144+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id: partitions revoked: [customer_visit_event_backup-2, customer_visit_event_backup-3]
2023-05-18T19:00:38.144+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id3: partitions revoked: [customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2]
2023-05-18T19:00:38.144+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id: partitions revoked: [customer_visit_event_backup-4, customer_visit_event_backup-5]
2023-05-18T19:00:38.143+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] Revoke previously assigned partitions customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2, customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5
2023-05-18T19:00:38.144+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id2: partitions revoked: [customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2, customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5]
2023-05-18T19:00:38.144+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] Member consumer-group_id-8-2cd984dc-ee12-40c0-a718-14f988e6f821 sending LeaveGroup request to coordinator b4-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 2147483643 rack: null) due to the consumer unsubscribed from all topics
2023-05-18T19:00:38.144+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] Member consumer-group_id2-9-38fa465b-7245-42d8-a39e-cf3b2f5fadc9 sending LeaveGroup request to coordinator b0-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2023-05-18T19:00:38.144+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-7, groupId=group_id] Member consumer-group_id-7-619b3ee0-e960-46e0-9f40-d97eeeac4144 sending LeaveGroup request to coordinator b4-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 2147483643 rack: null) due to the consumer unsubscribed from all topics
2023-05-18T19:00:38.144+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] Revoke previously assigned partitions customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5
2023-05-18T19:00:38.144+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-05-18T19:00:38.144+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] Request joining group due to: consumer pro-actively leaving the group
2023-05-18T19:00:38.144+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] Unsubscribed all topics or patterns and assigned partitions
2023-05-18T19:00:38.144+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-7, groupId=group_id] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-05-18T19:00:38.144+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-7, groupId=group_id] Request joining group due to: consumer pro-actively leaving the group
2023-05-18T19:00:38.144+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-11, groupId=group_id3] Member consumer-group_id3-11-e8463e1a-5e49-40ca-b5c2-23e3df7b5882 sending LeaveGroup request to coordinator b8-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 2147483639 rack: null) due to the consumer unsubscribed from all topics
2023-05-18T19:00:38.144+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-group_id-7, groupId=group_id] Unsubscribed all topics or patterns and assigned partitions
2023-05-18T19:00:38.144+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-05-18T19:00:38.144+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] Request joining group due to: consumer pro-actively leaving the group
2023-05-18T19:00:38.144+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-group_id-8, groupId=group_id] Unsubscribed all topics or patterns and assigned partitions
2023-05-18T19:00:38.144+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id3: partitions revoked: [customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5]
2023-05-18T19:00:38.144+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-11, groupId=group_id3] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-05-18T19:00:38.144+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-11, groupId=group_id3] Request joining group due to: consumer pro-actively leaving the group
2023-05-18T19:00:38.144+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-group_id3-11, groupId=group_id3] Unsubscribed all topics or patterns and assigned partitions
2023-05-18T19:00:38.144+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] Member consumer-group_id3-12-43a76d57-9a77-4fc8-a30c-3ad987e62ef0 sending LeaveGroup request to coordinator b8-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 2147483639 rack: null) due to the consumer unsubscribed from all topics
2023-05-18T19:00:38.144+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-05-18T19:00:38.144+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-10, groupId=group_id] Revoke previously assigned partitions customer_visit_event_backup-0, customer_visit_event_backup-1
2023-05-18T19:00:38.144+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] Request joining group due to: consumer pro-actively leaving the group
2023-05-18T19:00:38.144+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] Unsubscribed all topics or patterns and assigned partitions
2023-05-18T19:00:38.144+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id: partitions revoked: [customer_visit_event_backup-0, customer_visit_event_backup-1]
2023-05-18T19:00:38.144+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-10, groupId=group_id] Member consumer-group_id-10-59abfd68-f379-4f71-b044-a1a587d7984d sending LeaveGroup request to coordinator b4-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 2147483643 rack: null) due to the consumer unsubscribed from all topics
2023-05-18T19:00:38.145+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-10, groupId=group_id] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-05-18T19:00:38.145+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-10, groupId=group_id] Request joining group due to: consumer pro-actively leaving the group
2023-05-18T19:00:38.145+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-group_id-10, groupId=group_id] Unsubscribed all topics or patterns and assigned partitions
2023-05-18T19:00:38.145+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-05-18T19:00:38.145+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-9, groupId=group_id2] Request joining group due to: consumer pro-actively leaving the group
2023-05-18T19:00:38.146+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-05-18T19:00:38.146+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-7, groupId=group_id] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-05-18T19:00:38.146+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-8, groupId=group_id] Request joining group due to: consumer pro-actively leaving the group
2023-05-18T19:00:38.146+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-7, groupId=group_id] Request joining group due to: consumer pro-actively leaving the group
2023-05-18T19:00:38.146+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-10, groupId=group_id] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-05-18T19:00:38.146+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-10, groupId=group_id] Request joining group due to: consumer pro-actively leaving the group
2023-05-18T19:00:38.146+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-05-18T19:00:38.146+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-12, groupId=group_id3] Request joining group due to: consumer pro-actively leaving the group
2023-05-18T19:00:38.147+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-11, groupId=group_id3] Resetting generation and member id due to: consumer pro-actively leaving the group
2023-05-18T19:00:38.147+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-11, groupId=group_id3] Request joining group due to: consumer pro-actively leaving the group
2023-05-18T19:00:38.198+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-05-18T19:00:38.198+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-05-18T19:00:38.198+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-05-18T19:00:38.198+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-05-18T19:00:38.198+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-05-18T19:00:38.198+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-05-18T19:00:38.201+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-05-18T19:00:38.201+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-05-18T19:00:38.201+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-05-18T19:00:38.204+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-group_id-8 unregistered
2023-05-18T19:00:38.204+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id: Consumer stopped
2023-05-18T19:00:38.204+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-05-18T19:00:38.204+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-05-18T19:00:38.205+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-05-18T19:00:38.205+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-group_id2-9 unregistered
2023-05-18T19:00:38.205+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-05-18T19:00:38.205+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id2: Consumer stopped
2023-05-18T19:00:38.205+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-05-18T19:00:38.206+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-05-18T19:00:38.206+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-05-18T19:00:38.207+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-05-18T19:00:38.207+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-05-18T19:00:38.209+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-group_id-10 unregistered
2023-05-18T19:00:38.209+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id: Consumer stopped
2023-05-18T19:00:38.213+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-group_id-7 unregistered
2023-05-18T19:00:38.213+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id: Consumer stopped
2023-05-18T19:00:38.213+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-group_id3-12 unregistered
2023-05-18T19:00:38.213+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id3: Consumer stopped
2023-05-18T19:00:38.214+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for consumer-group_id3-11 unregistered
2023-05-18T19:00:38.215+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id3: Consumer stopped
2023-05-18T19:00:38.225+03:00  INFO 8268 --- [       Thread-7] o.apache.catalina.core.StandardService   : Stopping service [Tomcat]
2023-05-18T19:00:38.226+03:00  INFO 8268 --- [       Thread-7] o.a.c.c.C.[Tomcat].[localhost].[/]       : Destroying Spring FrameworkServlet 'dispatcherServlet'
2023-05-18T19:00:38.230+03:00  WARN 8268 --- [       Thread-7] o.a.c.loader.WebappClassLoaderBase       : The web application [ROOT] appears to have started a thread named [kafka-producer-network-thread | producer-2] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/sun.nio.ch.WEPoll.wait(Native Method)
 java.base@17.0.6/sun.nio.ch.WEPollSelectorImpl.doSelect(WEPollSelectorImpl.java:111)
 java.base@17.0.6/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
 java.base@17.0.6/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:141)
 app//org.apache.kafka.common.network.Selector.select(Selector.java:873)
 app//org.apache.kafka.common.network.Selector.poll(Selector.java:465)
 app//org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:560)
 app//org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:328)
 app//org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:243)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-05-18T19:00:38.233+03:00  INFO 8268 --- [       Thread-7] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 30000 ms.
2023-05-18T19:00:38.235+03:00  INFO 8268 --- [       Thread-7] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2023-05-18T19:00:38.235+03:00  INFO 8268 --- [       Thread-7] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-05-18T19:00:38.235+03:00  INFO 8268 --- [       Thread-7] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2023-05-18T19:00:38.235+03:00  INFO 8268 --- [       Thread-7] o.a.kafka.common.utils.AppInfoParser     : App info kafka.producer for producer-2 unregistered

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::                (v3.0.6)

2023-05-18T19:00:38.325+03:00  INFO 8268 --- [  restartedMain] c.a.spring.boot.kafka.KafkaApplication   : Starting KafkaApplication using Java 17.0.6 with PID 8268 (C:\Users\aziub\git\SpringBoot\kafka\target\classes started by aziub in C:\Users\aziub\git\SpringBoot\kafka)
2023-05-18T19:00:38.325+03:00  INFO 8268 --- [  restartedMain] c.a.spring.boot.kafka.KafkaApplication   : No active profile set, falling back to 1 default profile: "default"
2023-05-18T19:00:38.616+03:00  INFO 8268 --- [  restartedMain] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 8080 (http)
2023-05-18T19:00:38.616+03:00  INFO 8268 --- [  restartedMain] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2023-05-18T19:00:38.616+03:00  INFO 8268 --- [  restartedMain] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/10.1.8]
2023-05-18T19:00:38.636+03:00  INFO 8268 --- [  restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2023-05-18T19:00:38.636+03:00  INFO 8268 --- [  restartedMain] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 305 ms
2023-05-18T19:00:38.787+03:00  INFO 8268 --- [  restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : LiveReload server is running on port 35729
2023-05-18T19:00:38.808+03:00  INFO 8268 --- [  restartedMain] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8080 (http) with context path ''
2023-05-18T19:00:38.811+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-4nmjv.francecentral.azure.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_id-13
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-05-18T19:00:38.868+03:00  INFO 8268 --- [  restartedMain] o.a.k.c.s.authenticator.AbstractLogin    : Successfully logged in.
2023-05-18T19:00:38.877+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.2
2023-05-18T19:00:38.877+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: b66af662e61082cb
2023-05-18T19:00:38.877+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1684425638877
2023-05-18T19:00:38.877+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-group_id-13, groupId=group_id] Subscribed to topic(s): customer_visit_event_backup
2023-05-18T19:00:38.880+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-4nmjv.francecentral.azure.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_id-14
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-05-18T19:00:38.886+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.2
2023-05-18T19:00:38.886+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: b66af662e61082cb
2023-05-18T19:00:38.886+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1684425638886
2023-05-18T19:00:38.886+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-group_id-14, groupId=group_id] Subscribed to topic(s): customer_visit_event_backup
2023-05-18T19:00:38.890+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-4nmjv.francecentral.azure.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_id2-15
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-05-18T19:00:38.895+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.2
2023-05-18T19:00:38.895+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: b66af662e61082cb
2023-05-18T19:00:38.895+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1684425638895
2023-05-18T19:00:38.895+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-group_id2-15, groupId=group_id2] Subscribed to topic(s): customer_visit_event_backup
2023-05-18T19:00:38.898+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-4nmjv.francecentral.azure.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_id-16
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-05-18T19:00:38.904+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.2
2023-05-18T19:00:38.904+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: b66af662e61082cb
2023-05-18T19:00:38.904+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1684425638904
2023-05-18T19:00:38.904+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-group_id-16, groupId=group_id] Subscribed to topic(s): customer_visit_event_backup
2023-05-18T19:00:38.909+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-4nmjv.francecentral.azure.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_id4-17
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id4
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-05-18T19:00:38.913+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.2
2023-05-18T19:00:38.913+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: b66af662e61082cb
2023-05-18T19:00:38.913+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1684425638913
2023-05-18T19:00:38.914+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-group_id4-17, groupId=group_id4] Subscribed to topic(s): customer_visit_event_backup
2023-05-18T19:00:38.921+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-4nmjv.francecentral.azure.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_id3-18
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id3
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-05-18T19:00:38.927+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.2
2023-05-18T19:00:38.928+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: b66af662e61082cb
2023-05-18T19:00:38.928+03:00  INFO 8268 --- [  restartedMain] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1684425638927
2023-05-18T19:00:38.928+03:00  INFO 8268 --- [  restartedMain] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-group_id3-18, groupId=group_id3] Subscribed to topic(s): customer_visit_event_backup
2023-05-18T19:00:38.932+03:00  INFO 8268 --- [  restartedMain] c.a.spring.boot.kafka.KafkaApplication   : Started KafkaApplication in 0.644 seconds (process running for 171.058)
2023-05-18T19:00:38.932+03:00  INFO 8268 --- [  restartedMain] .ConditionEvaluationDeltaLoggingListener : Condition evaluation unchanged
2023-05-18T19:00:39.312+03:00  INFO 8268 --- [ntainer#2-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-13, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-0 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.312+03:00  INFO 8268 --- [ntainer#2-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-13, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-5 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.312+03:00  INFO 8268 --- [ntainer#2-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-13, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-4 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.312+03:00  INFO 8268 --- [ntainer#2-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-13, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-1 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.312+03:00  INFO 8268 --- [ntainer#2-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-13, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-2 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.312+03:00  INFO 8268 --- [ntainer#2-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-13, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-3 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.313+03:00  INFO 8268 --- [ntainer#2-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-13, groupId=group_id] Cluster ID: lkc-3rx3p2
2023-05-18T19:00:39.313+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-13, groupId=group_id] Discovered group coordinator b4-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 2147483643 rack: null)
2023-05-18T19:00:39.320+03:00  INFO 8268 --- [ntainer#5-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-16, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-0 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.320+03:00  INFO 8268 --- [ntainer#5-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-16, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-5 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.320+03:00  INFO 8268 --- [ntainer#5-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-16, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-4 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.321+03:00  INFO 8268 --- [ntainer#5-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-16, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-1 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.321+03:00  INFO 8268 --- [ntainer#5-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-16, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-2 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.321+03:00  INFO 8268 --- [ntainer#5-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-16, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-3 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.321+03:00  INFO 8268 --- [ntainer#5-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-16, groupId=group_id] Cluster ID: lkc-3rx3p2
2023-05-18T19:00:39.321+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-16, groupId=group_id] Discovered group coordinator b4-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 2147483643 rack: null)
2023-05-18T19:00:39.335+03:00  INFO 8268 --- [ntainer#4-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id2-15, groupId=group_id2] Resetting the last seen epoch of partition customer_visit_event_backup-0 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.336+03:00  INFO 8268 --- [ntainer#4-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id2-15, groupId=group_id2] Resetting the last seen epoch of partition customer_visit_event_backup-5 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.336+03:00  INFO 8268 --- [ntainer#4-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id2-15, groupId=group_id2] Resetting the last seen epoch of partition customer_visit_event_backup-4 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.336+03:00  INFO 8268 --- [ntainer#4-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id2-15, groupId=group_id2] Resetting the last seen epoch of partition customer_visit_event_backup-1 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.336+03:00  INFO 8268 --- [ntainer#4-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id2-15, groupId=group_id2] Resetting the last seen epoch of partition customer_visit_event_backup-2 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.336+03:00  INFO 8268 --- [ntainer#4-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id2-15, groupId=group_id2] Resetting the last seen epoch of partition customer_visit_event_backup-3 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.336+03:00  INFO 8268 --- [ntainer#4-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id2-15, groupId=group_id2] Cluster ID: lkc-3rx3p2
2023-05-18T19:00:39.337+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-15, groupId=group_id2] Discovered group coordinator b0-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 2147483647 rack: null)
2023-05-18T19:00:39.351+03:00  INFO 8268 --- [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id4-17, groupId=group_id4] Resetting the last seen epoch of partition customer_visit_event_backup-0 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.351+03:00  INFO 8268 --- [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id4-17, groupId=group_id4] Resetting the last seen epoch of partition customer_visit_event_backup-5 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.351+03:00  INFO 8268 --- [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id4-17, groupId=group_id4] Resetting the last seen epoch of partition customer_visit_event_backup-4 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.351+03:00  INFO 8268 --- [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id4-17, groupId=group_id4] Resetting the last seen epoch of partition customer_visit_event_backup-1 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.351+03:00  INFO 8268 --- [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id4-17, groupId=group_id4] Resetting the last seen epoch of partition customer_visit_event_backup-2 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.351+03:00  INFO 8268 --- [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id4-17, groupId=group_id4] Resetting the last seen epoch of partition customer_visit_event_backup-3 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.351+03:00  INFO 8268 --- [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id4-17, groupId=group_id4] Cluster ID: lkc-3rx3p2
2023-05-18T19:00:39.351+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id4-17, groupId=group_id4] Discovered group coordinator b8-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 2147483639 rack: null)
2023-05-18T19:00:39.361+03:00  INFO 8268 --- [ntainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-18, groupId=group_id3] Resetting the last seen epoch of partition customer_visit_event_backup-0 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.362+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-13, groupId=group_id] (Re-)joining group
2023-05-18T19:00:39.362+03:00  INFO 8268 --- [ntainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-18, groupId=group_id3] Resetting the last seen epoch of partition customer_visit_event_backup-5 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.362+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-16, groupId=group_id] (Re-)joining group
2023-05-18T19:00:39.362+03:00  INFO 8268 --- [ntainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-18, groupId=group_id3] Resetting the last seen epoch of partition customer_visit_event_backup-4 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.362+03:00  INFO 8268 --- [ntainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-18, groupId=group_id3] Resetting the last seen epoch of partition customer_visit_event_backup-1 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.362+03:00  INFO 8268 --- [ntainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-18, groupId=group_id3] Resetting the last seen epoch of partition customer_visit_event_backup-2 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.362+03:00  INFO 8268 --- [ntainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-18, groupId=group_id3] Resetting the last seen epoch of partition customer_visit_event_backup-3 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.362+03:00  INFO 8268 --- [ntainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id3-18, groupId=group_id3] Cluster ID: lkc-3rx3p2
2023-05-18T19:00:39.363+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-18, groupId=group_id3] Discovered group coordinator b8-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 2147483639 rack: null)
2023-05-18T19:00:39.372+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id4-17, groupId=group_id4] (Re-)joining group
2023-05-18T19:00:39.372+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-18, groupId=group_id3] (Re-)joining group
2023-05-18T19:00:39.399+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-15, groupId=group_id2] (Re-)joining group
2023-05-18T19:00:39.408+03:00  INFO 8268 --- [ntainer#3-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-14, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-0 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.408+03:00  INFO 8268 --- [ntainer#3-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-14, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-5 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.408+03:00  INFO 8268 --- [ntainer#3-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-14, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-4 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.408+03:00  INFO 8268 --- [ntainer#3-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-14, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-1 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.408+03:00  INFO 8268 --- [ntainer#3-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-14, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-2 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.408+03:00  INFO 8268 --- [ntainer#3-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-14, groupId=group_id] Resetting the last seen epoch of partition customer_visit_event_backup-3 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:39.408+03:00  INFO 8268 --- [ntainer#3-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-group_id-14, groupId=group_id] Cluster ID: lkc-3rx3p2
2023-05-18T19:00:39.408+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-14, groupId=group_id] Discovered group coordinator b4-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 2147483643 rack: null)
2023-05-18T19:00:39.409+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-14, groupId=group_id] (Re-)joining group
2023-05-18T19:00:39.784+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-16, groupId=group_id] Request joining group due to: need to re-join with the given member-id: consumer-group_id-16-7028f76b-68d5-4a84-a0f1-8bc14545eb63
2023-05-18T19:00:39.784+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-16, groupId=group_id] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-05-18T19:00:39.784+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-16, groupId=group_id] (Re-)joining group
2023-05-18T19:00:39.797+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id4-17, groupId=group_id4] Request joining group due to: need to re-join with the given member-id: consumer-group_id4-17-56ca34b6-8193-47db-9e07-2e2a4b91d803
2023-05-18T19:00:39.797+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id4-17, groupId=group_id4] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-05-18T19:00:39.797+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id4-17, groupId=group_id4] (Re-)joining group
2023-05-18T19:00:39.807+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-13, groupId=group_id] Request joining group due to: need to re-join with the given member-id: consumer-group_id-13-a2de0ae1-1b61-4066-bba7-ce473a06c356
2023-05-18T19:00:39.807+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-13, groupId=group_id] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-05-18T19:00:39.807+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-13, groupId=group_id] (Re-)joining group
2023-05-18T19:00:39.824+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-15, groupId=group_id2] Request joining group due to: need to re-join with the given member-id: consumer-group_id2-15-84859342-8757-4dd1-b9ce-430767b9d3ab
2023-05-18T19:00:39.824+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-15, groupId=group_id2] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-05-18T19:00:39.824+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-15, groupId=group_id2] (Re-)joining group
2023-05-18T19:00:39.837+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-16, groupId=group_id] Successfully joined group with generation Generation{generationId=95, memberId='consumer-group_id-16-7028f76b-68d5-4a84-a0f1-8bc14545eb63', protocol='range'}
2023-05-18T19:00:39.837+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-16, groupId=group_id] Finished assignment for group at generation 95: {consumer-group_id-16-7028f76b-68d5-4a84-a0f1-8bc14545eb63=Assignment(partitions=[customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2, customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5])}
2023-05-18T19:00:39.848+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id4-17, groupId=group_id4] Successfully joined group with generation Generation{generationId=1, memberId='consumer-group_id4-17-56ca34b6-8193-47db-9e07-2e2a4b91d803', protocol='range'}
2023-05-18T19:00:39.848+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id4-17, groupId=group_id4] Finished assignment for group at generation 1: {consumer-group_id4-17-56ca34b6-8193-47db-9e07-2e2a4b91d803=Assignment(partitions=[customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2, customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5])}
2023-05-18T19:00:39.861+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-14, groupId=group_id] Request joining group due to: need to re-join with the given member-id: consumer-group_id-14-58ee056a-b4b7-46a9-ab8f-ef79502ae125
2023-05-18T19:00:39.862+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-14, groupId=group_id] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-05-18T19:00:39.862+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-14, groupId=group_id] (Re-)joining group
2023-05-18T19:00:39.872+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-15, groupId=group_id2] Successfully joined group with generation Generation{generationId=68, memberId='consumer-group_id2-15-84859342-8757-4dd1-b9ce-430767b9d3ab', protocol='range'}
2023-05-18T19:00:39.872+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-15, groupId=group_id2] Finished assignment for group at generation 68: {consumer-group_id2-15-84859342-8757-4dd1-b9ce-430767b9d3ab=Assignment(partitions=[customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2, customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5])}
2023-05-18T19:00:39.889+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-16, groupId=group_id] SyncGroup failed: The group began another rebalance. Need to re-join the group. Sent generation was Generation{generationId=95, memberId='consumer-group_id-16-7028f76b-68d5-4a84-a0f1-8bc14545eb63', protocol='range'}
2023-05-18T19:00:39.889+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-16, groupId=group_id] Request joining group due to: rebalance failed due to 'The group is rebalancing, so a rejoin is needed.' (RebalanceInProgressException)
2023-05-18T19:00:39.889+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-16, groupId=group_id] (Re-)joining group
2023-05-18T19:00:39.895+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-18, groupId=group_id3] Request joining group due to: need to re-join with the given member-id: consumer-group_id3-18-4150f034-feeb-47f7-8aa5-6e1e147954c2
2023-05-18T19:00:39.895+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-18, groupId=group_id3] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2023-05-18T19:00:39.895+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-18, groupId=group_id3] (Re-)joining group
2023-05-18T19:00:39.905+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id4-17, groupId=group_id4] Successfully synced group in generation Generation{generationId=1, memberId='consumer-group_id4-17-56ca34b6-8193-47db-9e07-2e2a4b91d803', protocol='range'}
2023-05-18T19:00:39.906+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id4-17, groupId=group_id4] Notifying assignor about the new Assignment(partitions=[customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2, customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5])
2023-05-18T19:00:39.906+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id4-17, groupId=group_id4] Adding newly assigned partitions: customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2, customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5
2023-05-18T19:00:39.922+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-15, groupId=group_id2] Successfully synced group in generation Generation{generationId=68, memberId='consumer-group_id2-15-84859342-8757-4dd1-b9ce-430767b9d3ab', protocol='range'}
2023-05-18T19:00:39.922+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-15, groupId=group_id2] Notifying assignor about the new Assignment(partitions=[customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2, customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5])
2023-05-18T19:00:39.922+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-15, groupId=group_id2] Adding newly assigned partitions: customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2, customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5
2023-05-18T19:00:39.940+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-13, groupId=group_id] Successfully joined group with generation Generation{generationId=96, memberId='consumer-group_id-13-a2de0ae1-1b61-4066-bba7-ce473a06c356', protocol='range'}
2023-05-18T19:00:39.940+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-14, groupId=group_id] Successfully joined group with generation Generation{generationId=96, memberId='consumer-group_id-14-58ee056a-b4b7-46a9-ab8f-ef79502ae125', protocol='range'}
2023-05-18T19:00:39.941+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-16, groupId=group_id] Successfully joined group with generation Generation{generationId=96, memberId='consumer-group_id-16-7028f76b-68d5-4a84-a0f1-8bc14545eb63', protocol='range'}
2023-05-18T19:00:39.941+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-16, groupId=group_id] Finished assignment for group at generation 96: {consumer-group_id-13-a2de0ae1-1b61-4066-bba7-ce473a06c356=Assignment(partitions=[customer_visit_event_backup-0, customer_visit_event_backup-1]), consumer-group_id-14-58ee056a-b4b7-46a9-ab8f-ef79502ae125=Assignment(partitions=[customer_visit_event_backup-2, customer_visit_event_backup-3]), consumer-group_id-16-7028f76b-68d5-4a84-a0f1-8bc14545eb63=Assignment(partitions=[customer_visit_event_backup-4, customer_visit_event_backup-5])}
2023-05-18T19:00:39.951+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-18, groupId=group_id3] Successfully joined group with generation Generation{generationId=76, memberId='consumer-group_id3-18-4150f034-feeb-47f7-8aa5-6e1e147954c2', protocol='range'}
2023-05-18T19:00:39.951+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-18, groupId=group_id3] Finished assignment for group at generation 76: {consumer-group_id3-18-4150f034-feeb-47f7-8aa5-6e1e147954c2=Assignment(partitions=[customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2, customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5])}
2023-05-18T19:00:39.955+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id4-17, groupId=group_id4] Found no committed offset for partition customer_visit_event_backup-2
2023-05-18T19:00:39.955+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id4-17, groupId=group_id4] Found no committed offset for partition customer_visit_event_backup-3
2023-05-18T19:00:39.955+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id4-17, groupId=group_id4] Found no committed offset for partition customer_visit_event_backup-4
2023-05-18T19:00:39.955+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id4-17, groupId=group_id4] Found no committed offset for partition customer_visit_event_backup-5
2023-05-18T19:00:39.955+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id4-17, groupId=group_id4] Found no committed offset for partition customer_visit_event_backup-0
2023-05-18T19:00:39.955+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id4-17, groupId=group_id4] Found no committed offset for partition customer_visit_event_backup-1
2023-05-18T19:00:39.972+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-15, groupId=group_id2] Found no committed offset for partition customer_visit_event_backup-3
2023-05-18T19:00:39.972+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-15, groupId=group_id2] Found no committed offset for partition customer_visit_event_backup-4
2023-05-18T19:00:39.972+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-15, groupId=group_id2] Found no committed offset for partition customer_visit_event_backup-0
2023-05-18T19:00:39.972+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-15, groupId=group_id2] Found no committed offset for partition customer_visit_event_backup-1
2023-05-18T19:00:39.972+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-15, groupId=group_id2] Setting offset for partition customer_visit_event_backup-2 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b11-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 11 rack: 2)], epoch=0}}
2023-05-18T19:00:39.972+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id2-15, groupId=group_id2] Setting offset for partition customer_visit_event_backup-5 to the committed offset FetchPosition{offset=2, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b8-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 8 rack: 2)], epoch=0}}
2023-05-18T19:00:40.001+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-13, groupId=group_id] Successfully synced group in generation Generation{generationId=96, memberId='consumer-group_id-13-a2de0ae1-1b61-4066-bba7-ce473a06c356', protocol='range'}
2023-05-18T19:00:40.001+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-16, groupId=group_id] Successfully synced group in generation Generation{generationId=96, memberId='consumer-group_id-16-7028f76b-68d5-4a84-a0f1-8bc14545eb63', protocol='range'}
2023-05-18T19:00:40.001+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-14, groupId=group_id] Successfully synced group in generation Generation{generationId=96, memberId='consumer-group_id-14-58ee056a-b4b7-46a9-ab8f-ef79502ae125', protocol='range'}
2023-05-18T19:00:40.001+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-13, groupId=group_id] Notifying assignor about the new Assignment(partitions=[customer_visit_event_backup-0, customer_visit_event_backup-1])
2023-05-18T19:00:40.001+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-13, groupId=group_id] Adding newly assigned partitions: customer_visit_event_backup-0, customer_visit_event_backup-1
2023-05-18T19:00:40.001+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-14, groupId=group_id] Notifying assignor about the new Assignment(partitions=[customer_visit_event_backup-2, customer_visit_event_backup-3])
2023-05-18T19:00:40.001+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-14, groupId=group_id] Adding newly assigned partitions: customer_visit_event_backup-2, customer_visit_event_backup-3
2023-05-18T19:00:40.002+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-16, groupId=group_id] Notifying assignor about the new Assignment(partitions=[customer_visit_event_backup-4, customer_visit_event_backup-5])
2023-05-18T19:00:40.003+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-16, groupId=group_id] Adding newly assigned partitions: customer_visit_event_backup-4, customer_visit_event_backup-5
2023-05-18T19:00:40.011+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-18, groupId=group_id3] Successfully synced group in generation Generation{generationId=76, memberId='consumer-group_id3-18-4150f034-feeb-47f7-8aa5-6e1e147954c2', protocol='range'}
2023-05-18T19:00:40.012+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-18, groupId=group_id3] Notifying assignor about the new Assignment(partitions=[customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2, customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5])
2023-05-18T19:00:40.013+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-18, groupId=group_id3] Adding newly assigned partitions: customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2, customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5
2023-05-18T19:00:40.055+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-16, groupId=group_id] Found no committed offset for partition customer_visit_event_backup-4
2023-05-18T19:00:40.055+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-16, groupId=group_id] Setting offset for partition customer_visit_event_backup-5 to the committed offset FetchPosition{offset=2, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b8-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 8 rack: 2)], epoch=0}}
2023-05-18T19:00:40.056+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-14, groupId=group_id] Found no committed offset for partition customer_visit_event_backup-3
2023-05-18T19:00:40.056+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-14, groupId=group_id] Setting offset for partition customer_visit_event_backup-2 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b11-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 11 rack: 2)], epoch=0}}
2023-05-18T19:00:40.057+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-13, groupId=group_id] Found no committed offset for partition customer_visit_event_backup-0
2023-05-18T19:00:40.057+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id-13, groupId=group_id] Found no committed offset for partition customer_visit_event_backup-1
2023-05-18T19:00:40.069+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-18, groupId=group_id3] Found no committed offset for partition customer_visit_event_backup-3
2023-05-18T19:00:40.069+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-18, groupId=group_id3] Found no committed offset for partition customer_visit_event_backup-4
2023-05-18T19:00:40.069+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-18, groupId=group_id3] Found no committed offset for partition customer_visit_event_backup-0
2023-05-18T19:00:40.069+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-18, groupId=group_id3] Found no committed offset for partition customer_visit_event_backup-1
2023-05-18T19:00:40.070+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-18, groupId=group_id3] Setting offset for partition customer_visit_event_backup-2 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b11-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 11 rack: 2)], epoch=0}}
2023-05-18T19:00:40.070+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-group_id3-18, groupId=group_id3] Setting offset for partition customer_visit_event_backup-5 to the committed offset FetchPosition{offset=2, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b8-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 8 rack: 2)], epoch=0}}
2023-05-18T19:00:40.516+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id4-17, groupId=group_id4] Resetting offset for partition customer_visit_event_backup-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b8-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 8 rack: 2)], epoch=0}}.
2023-05-18T19:00:40.535+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id2-15, groupId=group_id2] Resetting offset for partition customer_visit_event_backup-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b7-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 7 rack: 1)], epoch=0}}.
2023-05-18T19:00:40.536+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id2-15, groupId=group_id2] Resetting offset for partition customer_visit_event_backup-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b9-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 9 rack: 0)], epoch=0}}.
2023-05-18T19:00:40.540+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id-13, groupId=group_id] Resetting offset for partition customer_visit_event_backup-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b7-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 7 rack: 1)], epoch=0}}.
2023-05-18T19:00:40.541+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id-13, groupId=group_id] Resetting offset for partition customer_visit_event_backup-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b9-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 9 rack: 0)], epoch=0}}.
2023-05-18T19:00:40.542+03:00  INFO 8268 --- [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id: partitions assigned: [customer_visit_event_backup-0, customer_visit_event_backup-1]
2023-05-18T19:00:40.552+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id3-18, groupId=group_id3] Resetting offset for partition customer_visit_event_backup-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b7-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 7 rack: 1)], epoch=0}}.
2023-05-18T19:00:40.560+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id3-18, groupId=group_id3] Resetting offset for partition customer_visit_event_backup-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b9-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 9 rack: 0)], epoch=0}}.
2023-05-18T19:00:40.570+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id3-18, groupId=group_id3] Resetting offset for partition customer_visit_event_backup-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b10-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 10 rack: 1)], epoch=0}}.
2023-05-18T19:00:40.572+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id2-15, groupId=group_id2] Resetting offset for partition customer_visit_event_backup-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b10-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 10 rack: 1)], epoch=0}}.
2023-05-18T19:00:40.572+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id-14, groupId=group_id] Resetting offset for partition customer_visit_event_backup-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b3-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 3 rack: 0)], epoch=0}}.
2023-05-18T19:00:40.572+03:00  INFO 8268 --- [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id: partitions assigned: [customer_visit_event_backup-2, customer_visit_event_backup-3]
2023-05-18T19:00:40.577+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id3-18, groupId=group_id3] Resetting offset for partition customer_visit_event_backup-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b3-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 3 rack: 0)], epoch=0}}.
2023-05-18T19:00:40.577+03:00  INFO 8268 --- [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id3: partitions assigned: [customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2, customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5]
2023-05-18T19:00:40.578+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id4-17, groupId=group_id4] Resetting offset for partition customer_visit_event_backup-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b9-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 9 rack: 0)], epoch=0}}.
2023-05-18T19:00:40.579+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id4-17, groupId=group_id4] Resetting offset for partition customer_visit_event_backup-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b7-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 7 rack: 1)], epoch=0}}.
2023-05-18T19:00:40.587+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id-16, groupId=group_id] Resetting offset for partition customer_visit_event_backup-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b10-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 10 rack: 1)], epoch=0}}.
2023-05-18T19:00:40.587+03:00  INFO 8268 --- [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id: partitions assigned: [customer_visit_event_backup-4, customer_visit_event_backup-5]
2023-05-18T19:00:40.592+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id4-17, groupId=group_id4] Resetting offset for partition customer_visit_event_backup-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b10-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 10 rack: 1)], epoch=0}}.
2023-05-18T19:00:40.613+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id4-17, groupId=group_id4] Resetting offset for partition customer_visit_event_backup-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b3-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 3 rack: 0)], epoch=0}}.
2023-05-18T19:00:40.614+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id2-15, groupId=group_id2] Resetting offset for partition customer_visit_event_backup-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b3-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 3 rack: 0)], epoch=0}}.
2023-05-18T19:00:40.614+03:00  INFO 8268 --- [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id2: partitions assigned: [customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2, customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5]
2023-05-18T19:00:40.618+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-group_id4-17, groupId=group_id4] Resetting offset for partition customer_visit_event_backup-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b11-pkc-4nmjv.francecentral.azure.confluent.cloud:9092 (id: 11 rack: 2)], epoch=0}}.
2023-05-18T19:00:40.619+03:00  INFO 8268 --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_id4: partitions assigned: [customer_visit_event_backup-0, customer_visit_event_backup-1, customer_visit_event_backup-2, customer_visit_event_backup-3, customer_visit_event_backup-4, customer_visit_event_backup-5]
2023-05-18T19:00:40.678+03:00  INFO 8268 --- [ntainer#0-0-C-1] s.b.k.KafkaApplication$RestfulController : Consumed CustomerVisitEvent group_id4; CustomerVisitEvent(customerId=658fe2f3-1300-4d68-b798-d3270007bef9, dateTime=2023-05-18T18:58:09.618097100)
2023-05-18T19:00:40.679+03:00  INFO 8268 --- [ntainer#0-0-C-1] s.b.k.KafkaApplication$RestfulController : Consumed CustomerVisitEvent group_id4; CustomerVisitEvent(customerId=ecfcf538-2d59-4565-96cc-3aa66ff5ad0a, dateTime=2023-05-18T18:59:52.986241)
2023-05-18T19:00:40.733+03:00  INFO 8268 --- [ntainer#0-0-C-1] s.b.k.KafkaApplication$RestfulController : Consumed CustomerVisitEvent group_id4; CustomerVisitEvent(customerId=4e562525-e51c-4693-8e4d-4cfb036c443a, dateTime=2023-05-18T18:50:43.926222700)
2023-05-18T19:00:41.300+03:00  INFO 8268 --- [nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-05-18T19:00:41.301+03:00  INFO 8268 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
2023-05-18T19:00:41.301+03:00  INFO 8268 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 0 ms
2023-05-18T19:00:43.270+03:00  INFO 8268 --- [nio-8080-exec-1] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [pkc-4nmjv.francecentral.azure.confluent.cloud:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-3
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2023-05-18T19:00:43.271+03:00  INFO 8268 --- [nio-8080-exec-1] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-3] Instantiated an idempotent producer.
2023-05-18T19:00:43.276+03:00  INFO 8268 --- [nio-8080-exec-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.3.2
2023-05-18T19:00:43.277+03:00  INFO 8268 --- [nio-8080-exec-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: b66af662e61082cb
2023-05-18T19:00:43.277+03:00  INFO 8268 --- [nio-8080-exec-1] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1684425643276
2023-05-18T19:00:43.705+03:00  INFO 8268 --- [ad | producer-3] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-3] Resetting the last seen epoch of partition customer_visit_event_backup-0 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:43.705+03:00  INFO 8268 --- [ad | producer-3] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-3] Resetting the last seen epoch of partition customer_visit_event_backup-5 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:43.705+03:00  INFO 8268 --- [ad | producer-3] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-3] Resetting the last seen epoch of partition customer_visit_event_backup-4 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:43.705+03:00  INFO 8268 --- [ad | producer-3] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-3] Resetting the last seen epoch of partition customer_visit_event_backup-1 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:43.705+03:00  INFO 8268 --- [ad | producer-3] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-3] Resetting the last seen epoch of partition customer_visit_event_backup-2 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:43.705+03:00  INFO 8268 --- [ad | producer-3] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-3] Resetting the last seen epoch of partition customer_visit_event_backup-3 to 0 since the associated topicId changed from null to 1Hdki9zkSU--iuaHj4Gc9A
2023-05-18T19:00:43.705+03:00  INFO 8268 --- [ad | producer-3] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-3] Cluster ID: lkc-3rx3p2
2023-05-18T19:00:43.705+03:00  INFO 8268 --- [ad | producer-3] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-3] ProducerId set to 9612636 with epoch 0
2023-05-18T19:00:44.154+03:00  INFO 8268 --- [ntainer#0-0-C-1] s.b.k.KafkaApplication$RestfulController : Consumed CustomerVisitEvent group_id4; CustomerVisitEvent(customerId=9b0659f6-917a-4b32-a7bf-ba27b10ad309, dateTime=2023-05-18T19:00:43.270660100)
2023-05-18T19:00:44.153+03:00 ERROR 8268 --- [ntainer#4-0-C-1] o.s.kafka.listener.DefaultErrorHandler   : Backoff FixedBackOff{interval=0, currentAttempts=1, maxAttempts=0} exhausted for customer_visit_event_backup-1@0

org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method could not be invoked with the incoming message
Endpoint handler details:
Method [public void com.aziubin.spring.boot.kafka.KafkaApplication$RestfulController.consume2(java.lang.String,org.apache.kafka.clients.consumer.ConsumerRecord) throws java.io.IOException]
Bean [com.aziubin.spring.boot.kafka.KafkaApplication$RestfulController@6a9f7c9a]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2988) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2933) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2899) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$58(KafkaMessageListenerContainer.java:2822) ~[spring-kafka-3.0.6.jar:3.0.6]
	at io.micrometer.observation.Observation.observe(Observation.java:562) ~[micrometer-observation-1.10.6.jar:1.10.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2820) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2672) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2558) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2200) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1555) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1519) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1394) ~[spring-kafka-3.0.6.jar:3.0.6]
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1804) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.checkAckArg(MessagingMessageListenerAdapter.java:393) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:371) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2919) ~[spring-kafka-3.0.6.jar:3.0.6]
Caused by: org.springframework.messaging.converter.MessageConversionException: Cannot handle message
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:371) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2919) ~[spring-kafka-3.0.6.jar:3.0.6]
	... 12 common frames omitted
Caused by: org.springframework.messaging.converter.MessageConversionException: Cannot convert from [com.aziubin.spring.boot.kafka.domain.CustomerVisitEvent] to [java.lang.String] for GenericMessage [payload=CustomerVisitEvent(customerId=9b0659f6-917a-4b32-a7bf-ba27b10ad309, dateTime=2023-05-18T19:00:43.270660100), headers={kafka_offset=0, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@212ff965, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=1, kafka_receivedTopic=customer_visit_event_backup, kafka_receivedTimestamp=1684425643705, kafka_groupId=group_id2}]
	at org.springframework.messaging.handler.annotation.support.PayloadMethodArgumentResolver.resolveArgument(PayloadMethodArgumentResolver.java:148) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.kafka.annotation.KafkaNullAwarePayloadArgumentResolver.resolveArgument(KafkaNullAwarePayloadArgumentResolver.java:46) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.messaging.handler.invocation.HandlerMethodArgumentResolverComposite.resolveArgument(HandlerMethodArgumentResolverComposite.java:118) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.getMethodArgumentValues(InvocableHandlerMethod.java:147) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:115) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:366) ~[spring-kafka-3.0.6.jar:3.0.6]
	... 15 common frames omitted

2023-05-18T19:00:44.153+03:00 ERROR 8268 --- [ntainer#2-0-C-1] o.s.kafka.listener.DefaultErrorHandler   : Backoff FixedBackOff{interval=0, currentAttempts=1, maxAttempts=0} exhausted for customer_visit_event_backup-1@0

org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method could not be invoked with the incoming message
Endpoint handler details:
Method [public void com.aziubin.spring.boot.kafka.KafkaApplication$RestfulController.consumeGroupIdC(java.lang.String) throws java.io.IOException]
Bean [com.aziubin.spring.boot.kafka.KafkaApplication$RestfulController@6a9f7c9a]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2988) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2933) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2899) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$58(KafkaMessageListenerContainer.java:2822) ~[spring-kafka-3.0.6.jar:3.0.6]
	at io.micrometer.observation.Observation.observe(Observation.java:562) ~[micrometer-observation-1.10.6.jar:1.10.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2820) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2672) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2558) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2200) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1555) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1519) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1394) ~[spring-kafka-3.0.6.jar:3.0.6]
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1804) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.checkAckArg(MessagingMessageListenerAdapter.java:393) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:371) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2919) ~[spring-kafka-3.0.6.jar:3.0.6]
Caused by: org.springframework.messaging.converter.MessageConversionException: Cannot handle message
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:371) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2919) ~[spring-kafka-3.0.6.jar:3.0.6]
	... 12 common frames omitted
Caused by: org.springframework.messaging.converter.MessageConversionException: Cannot convert from [com.aziubin.spring.boot.kafka.domain.CustomerVisitEvent] to [java.lang.String] for GenericMessage [payload=CustomerVisitEvent(customerId=9b0659f6-917a-4b32-a7bf-ba27b10ad309, dateTime=2023-05-18T19:00:43.270660100), headers={kafka_offset=0, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@44ceb7bd, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=1, kafka_receivedTopic=customer_visit_event_backup, kafka_receivedTimestamp=1684425643705, kafka_groupId=group_id}]
	at org.springframework.messaging.handler.annotation.support.PayloadMethodArgumentResolver.resolveArgument(PayloadMethodArgumentResolver.java:148) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.kafka.annotation.KafkaNullAwarePayloadArgumentResolver.resolveArgument(KafkaNullAwarePayloadArgumentResolver.java:46) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.messaging.handler.invocation.HandlerMethodArgumentResolverComposite.resolveArgument(HandlerMethodArgumentResolverComposite.java:118) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.getMethodArgumentValues(InvocableHandlerMethod.java:147) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:115) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:366) ~[spring-kafka-3.0.6.jar:3.0.6]
	... 15 common frames omitted

2023-05-18T19:00:44.153+03:00 ERROR 8268 --- [ntainer#1-0-C-1] o.s.kafka.listener.DefaultErrorHandler   : Backoff FixedBackOff{interval=0, currentAttempts=1, maxAttempts=0} exhausted for customer_visit_event_backup-1@0

org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method could not be invoked with the incoming message
Endpoint handler details:
Method [public void com.aziubin.spring.boot.kafka.KafkaApplication$RestfulController.consume3(java.lang.String,org.apache.kafka.clients.consumer.ConsumerRecord) throws java.io.IOException]
Bean [com.aziubin.spring.boot.kafka.KafkaApplication$RestfulController@6a9f7c9a]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2988) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2933) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2899) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$58(KafkaMessageListenerContainer.java:2822) ~[spring-kafka-3.0.6.jar:3.0.6]
	at io.micrometer.observation.Observation.observe(Observation.java:562) ~[micrometer-observation-1.10.6.jar:1.10.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2820) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2672) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2558) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2200) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1555) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1519) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1394) ~[spring-kafka-3.0.6.jar:3.0.6]
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1804) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
	Suppressed: org.springframework.kafka.listener.ListenerExecutionFailedException: Restored Stack Trace
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.checkAckArg(MessagingMessageListenerAdapter.java:393) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:371) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-3.0.6.jar:3.0.6]
		at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2919) ~[spring-kafka-3.0.6.jar:3.0.6]
Caused by: org.springframework.messaging.converter.MessageConversionException: Cannot handle message
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:371) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2919) ~[spring-kafka-3.0.6.jar:3.0.6]
	... 12 common frames omitted
Caused by: org.springframework.messaging.converter.MessageConversionException: Cannot convert from [com.aziubin.spring.boot.kafka.domain.CustomerVisitEvent] to [java.lang.String] for GenericMessage [payload=CustomerVisitEvent(customerId=9b0659f6-917a-4b32-a7bf-ba27b10ad309, dateTime=2023-05-18T19:00:43.270660100), headers={kafka_offset=0, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@5e90c041, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=1, kafka_receivedTopic=customer_visit_event_backup, kafka_receivedTimestamp=1684425643705, kafka_groupId=group_id3}]
	at org.springframework.messaging.handler.annotation.support.PayloadMethodArgumentResolver.resolveArgument(PayloadMethodArgumentResolver.java:148) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.kafka.annotation.KafkaNullAwarePayloadArgumentResolver.resolveArgument(KafkaNullAwarePayloadArgumentResolver.java:46) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.messaging.handler.invocation.HandlerMethodArgumentResolverComposite.resolveArgument(HandlerMethodArgumentResolverComposite.java:118) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.getMethodArgumentValues(InvocableHandlerMethod.java:147) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:115) ~[spring-messaging-6.0.8.jar:6.0.8]
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56) ~[spring-kafka-3.0.6.jar:3.0.6]
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:366) ~[spring-kafka-3.0.6.jar:3.0.6]
	... 15 common frames omitted

